[2025-11-07 06:54:21,886][_client.py][line:1025][INFO] HTTP Request: HEAD https://huggingface.co/bert-base-chinese/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2025-11-07 06:54:22,083][_client.py][line:1025][INFO] HTTP Request: GET https://huggingface.co/api/models/bert-base-chinese/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
[2025-11-07 06:54:22,277][_client.py][line:1025][INFO] HTTP Request: GET https://huggingface.co/api/models/google-bert/bert-base-chinese/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
[2025-11-07 06:54:22,500][_client.py][line:1025][INFO] HTTP Request: HEAD https://huggingface.co/bert-base-chinese/resolve/main/config.json "HTTP/1.1 200 OK"
[2025-11-07 06:54:22,695][_client.py][line:1025][INFO] HTTP Request: HEAD https://huggingface.co/bert-base-chinese/resolve/main/model.safetensors "HTTP/1.1 302 Found"
[2025-11-07 06:54:23,528][run_task2&3_trainer_multilingual.py][line:957][INFO] initial optimizer......
[2025-11-07 06:54:23,528][run_task2&3_trainer_multilingual.py][line:975][INFO] New model and optimizer from epoch 1
[2025-11-07 06:54:23,528][run_task2&3_trainer_multilingual.py][line:984][INFO] begin training......
[2025-11-07 06:54:26,691][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[10/968.0]	 Loss Sum:356.3296	forward Loss:66.2353;75.2779	 backward Loss:51.829;64.4197	 Sentiment Loss:17.9544	Valence Loss:204.6282	 Arousal Loss:198.4386	
[2025-11-07 06:54:29,709][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[20/968.0]	 Loss Sum:307.7791	forward Loss:56.7646;60.8583	 backward Loss:46.7656;60.3393	 Sentiment Loss:14.7952	Valence Loss:199.3026	 Arousal Loss:141.9774	
[2025-11-07 06:54:32,695][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[30/968.0]	 Loss Sum:238.8595	forward Loss:50.1927;44.648	 backward Loss:42.2988;47.9822	 Sentiment Loss:13.2009	Valence Loss:118.262	 Arousal Loss:84.4229	
[2025-11-07 06:54:35,572][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[40/968.0]	 Loss Sum:161.5178	forward Loss:34.6678;40.7745	 backward Loss:30.0132;35.973	 Sentiment Loss:8.2087	Valence Loss:38.5041	 Arousal Loss:20.899	
[2025-11-07 06:54:38,449][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[50/968.0]	 Loss Sum:122.7955	forward Loss:29.0649;26.9909	 backward Loss:24.8554;32.4188	 Sentiment Loss:8.5353	Valence Loss:1.9906	 Arousal Loss:2.6602	
[2025-11-07 06:54:41,379][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[60/968.0]	 Loss Sum:95.5105	forward Loss:21.8235;21.3064	 backward Loss:17.7637;26.8993	 Sentiment Loss:5.0645	Valence Loss:6.8157	 Arousal Loss:6.4494	
[2025-11-07 06:54:44,242][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[70/968.0]	 Loss Sum:106.3899	forward Loss:24.4828;21.3177	 backward Loss:22.1178;24.0255	 Sentiment Loss:11.2169	Valence Loss:14.3689	 Arousal Loss:1.7766	
[2025-11-07 06:54:47,119][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[80/968.0]	 Loss Sum:100.7092	forward Loss:20.1779;19.8387	 backward Loss:25.5596;22.8846	 Sentiment Loss:10.4944	Valence Loss:4.1055	 Arousal Loss:4.6644	
[2025-11-07 06:54:50,251][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[90/968.0]	 Loss Sum:51.5846	forward Loss:10.4753;14.068	 backward Loss:8.9878;10.2657	 Sentiment Loss:6.1006	Valence Loss:4.6872	 Arousal Loss:3.7491	
[2025-11-07 06:54:53,028][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[100/968.0]	 Loss Sum:58.6235	forward Loss:12.4457;16.3511	 backward Loss:12.0996;13.6596	 Sentiment Loss:3.6351	Valence Loss:0.5059	 Arousal Loss:1.6562	
[2025-11-07 06:54:56,150][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[110/968.0]	 Loss Sum:82.5281	forward Loss:19.9343;13.3868	 backward Loss:13.0107;23.3313	 Sentiment Loss:11.4022	Valence Loss:3.2659	 Arousal Loss:4.0486	
[2025-11-07 06:54:59,027][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[120/968.0]	 Loss Sum:31.6782	forward Loss:5.9195;5.9705	 backward Loss:4.5726;6.1201	 Sentiment Loss:6.8264	Valence Loss:10.3248	 Arousal Loss:1.0205	
[2025-11-07 06:55:01,969][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[130/968.0]	 Loss Sum:56.123	forward Loss:6.5875;20.8923	 backward Loss:17.1288;5.9239	 Sentiment Loss:4.6623	Valence Loss:3.2386	 Arousal Loss:1.4032	
[2025-11-07 06:55:04,848][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[140/968.0]	 Loss Sum:56.2039	forward Loss:10.7594;11.4202	 backward Loss:7.5705;11.6137	 Sentiment Loss:13.1383	Valence Loss:4.7389	 Arousal Loss:3.7697	
[2025-11-07 06:55:07,734][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[150/968.0]	 Loss Sum:46.1162	forward Loss:5.6313;8.356	 backward Loss:14.0861;9.8459	 Sentiment Loss:7.328	Valence Loss:2.8094	 Arousal Loss:1.5342	
[2025-11-07 06:55:10,611][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[160/968.0]	 Loss Sum:65.5575	forward Loss:21.9366;3.0419	 backward Loss:2.7657;29.5358	 Sentiment Loss:5.1587	Valence Loss:12.0505	 Arousal Loss:3.5437	
[2025-11-07 06:55:13,558][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[170/968.0]	 Loss Sum:65.6193	forward Loss:7.2523;25.775	 backward Loss:20.3959;9.6834	 Sentiment Loss:1.2108	Valence Loss:2.568	 Arousal Loss:3.9408	
[2025-11-07 06:55:16,435][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[180/968.0]	 Loss Sum:30.01	forward Loss:4.1847;6.5421	 backward Loss:6.6505;7.0652	 Sentiment Loss:2.9526	Valence Loss:10.7648	 Arousal Loss:2.3098	
[2025-11-07 06:55:19,585][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[190/968.0]	 Loss Sum:80.0013	forward Loss:8.036;27.3142	 backward Loss:23.3945;17.4467	 Sentiment Loss:2.5075	Valence Loss:1.955	 Arousal Loss:4.5567	
[2025-11-07 06:55:22,493][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[200/968.0]	 Loss Sum:88.2429	forward Loss:9.3363;33.455	 backward Loss:32.0554;8.3985	 Sentiment Loss:3.3804	Valence Loss:5.078	 Arousal Loss:3.009	
[2025-11-07 06:55:25,494][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[210/968.0]	 Loss Sum:23.9089	forward Loss:3.6955;8.3973	 backward Loss:2.8497;4.3893	 Sentiment Loss:3.4259	Valence Loss:4.3397	 Arousal Loss:1.4165	
[2025-11-07 06:55:28,378][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[220/968.0]	 Loss Sum:63.1604	forward Loss:16.4265;12.3575	 backward Loss:15.5147;12.4468	 Sentiment Loss:5.4922	Valence Loss:2.2382	 Arousal Loss:2.3755	
[2025-11-07 06:55:31,275][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[230/968.0]	 Loss Sum:61.6181	forward Loss:7.6096;21.4406	 backward Loss:19.2281;8.0994	 Sentiment Loss:2.6364	Valence Loss:6.8191	 Arousal Loss:6.2007	
[2025-11-07 06:55:34,225][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[240/968.0]	 Loss Sum:51.9184	forward Loss:9.7489;10.2209	 backward Loss:9.153;14.5651	 Sentiment Loss:6.3728	Valence Loss:4.4185	 Arousal Loss:4.8704	
[2025-11-07 06:55:37,125][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[250/968.0]	 Loss Sum:28.9059	forward Loss:3.1435;11.5338	 backward Loss:6.1608;3.988	 Sentiment Loss:1.7597	Valence Loss:9.1219	 Arousal Loss:2.4786	
[2025-11-07 06:55:39,997][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[260/968.0]	 Loss Sum:41.32	forward Loss:6.3457;12.1484	 backward Loss:10.8295;7.5515	 Sentiment Loss:3.3205	Valence Loss:3.0415	 Arousal Loss:2.5801	
[2025-11-07 06:55:43,033][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[270/968.0]	 Loss Sum:23.2861	forward Loss:3.1506;7.7321	 backward Loss:3.8534;4.407	 Sentiment Loss:2.8533	Valence Loss:5.44	 Arousal Loss:1.0089	
[2025-11-07 06:55:45,830][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[280/968.0]	 Loss Sum:37.2907	forward Loss:8.0582;7.7783	 backward Loss:6.9581;10.5262	 Sentiment Loss:0.1886	Valence Loss:18.0216	 Arousal Loss:0.8855	
[2025-11-07 06:55:48,982][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[290/968.0]	 Loss Sum:30.1771	forward Loss:5.4573;3.3366	 backward Loss:3.6744;12.4413	 Sentiment Loss:3.1245	Valence Loss:4.4486	 Arousal Loss:6.2664	
[2025-11-07 06:55:51,960][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[300/968.0]	 Loss Sum:41.013	forward Loss:10.2374;7.4237	 backward Loss:5.101;10.5813	 Sentiment Loss:7.1194	Valence Loss:0.9129	 Arousal Loss:1.8387	
[2025-11-07 06:55:54,919][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[310/968.0]	 Loss Sum:21.2219	forward Loss:3.1557;6.508	 backward Loss:7.0283;2.8473	 Sentiment Loss:0.7033	Valence Loss:2.169	 Arousal Loss:2.7272	
[2025-11-07 06:55:57,801][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[320/968.0]	 Loss Sum:66.2001	forward Loss:13.8855;11.9762	 backward Loss:12.2766;17.8225	 Sentiment Loss:8.392	Valence Loss:7.1969	 Arousal Loss:2.0389	
[2025-11-07 06:56:00,706][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[330/968.0]	 Loss Sum:36.8569	forward Loss:8.5087;10.49	 backward Loss:8.4124;7.033	 Sentiment Loss:1.5079	Valence Loss:2.2781	 Arousal Loss:2.2459	
[2025-11-07 06:56:03,595][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[340/968.0]	 Loss Sum:19.3567	forward Loss:4.5525;4.2545	 backward Loss:2.0491;6.3895	 Sentiment Loss:0.7196	Valence Loss:6.0661	 Arousal Loss:0.8909	
[2025-11-07 06:56:06,555][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[350/968.0]	 Loss Sum:27.9635	forward Loss:9.4116;6.4593	 backward Loss:5.3086;5.3925	 Sentiment Loss:0.7412	Valence Loss:1.6581	 Arousal Loss:1.5934	
[2025-11-07 06:56:09,432][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[360/968.0]	 Loss Sum:22.4997	forward Loss:3.3726;5.4605	 backward Loss:3.8005;3.8601	 Sentiment Loss:4.0759	Valence Loss:7.2688	 Arousal Loss:2.3817	
[2025-11-07 06:56:12,484][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[370/968.0]	 Loss Sum:39.3638	forward Loss:14.2551;8.5795	 backward Loss:7.8832;6.8736	 Sentiment Loss:1.1441	Valence Loss:1.7323	 Arousal Loss:1.4089	
[2025-11-07 06:56:15,497][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[380/968.0]	 Loss Sum:31.5942	forward Loss:5.3005;5.7247	 backward Loss:7.5592;10.7755	 Sentiment Loss:1.4465	Valence Loss:2.3335	 Arousal Loss:1.6058	
[2025-11-07 06:56:18,518][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[390/968.0]	 Loss Sum:20.613	forward Loss:3.6777;7.6976	 backward Loss:3.9066;3.7596	 Sentiment Loss:0.9627	Valence Loss:1.432	 Arousal Loss:1.6116	
[2025-11-07 06:56:21,403][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[400/968.0]	 Loss Sum:37.2874	forward Loss:6.3779;13.0812	 backward Loss:6.647;9.0067	 Sentiment Loss:1.8262	Valence Loss:1.2619	 Arousal Loss:0.4803	
[2025-11-07 06:56:24,305][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[410/968.0]	 Loss Sum:43.504	forward Loss:3.4596;13.7012	 backward Loss:13.8395;7.3461	 Sentiment Loss:4.3893	Valence Loss:1.6081	 Arousal Loss:2.2338	
[2025-11-07 06:56:27,257][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[420/968.0]	 Loss Sum:30.095	forward Loss:6.3479;7.3044	 backward Loss:5.0193;5.1687	 Sentiment Loss:5.7145	Valence Loss:1.093	 Arousal Loss:1.6083	
[2025-11-07 06:56:30,164][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[430/968.0]	 Loss Sum:32.5128	forward Loss:7.5333;8.9606	 backward Loss:5.3622;8.8119	 Sentiment Loss:1.3004	Valence Loss:1.4492	 Arousal Loss:1.2727	
[2025-11-07 06:56:33,048][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[440/968.0]	 Loss Sum:39.026	forward Loss:5.7742;7.6537	 backward Loss:16.3067;5.1848	 Sentiment Loss:2.9519	Valence Loss:3.7715	 Arousal Loss:2.0015	
[2025-11-07 06:56:36,101][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[450/968.0]	 Loss Sum:50.3457	forward Loss:14.7414;9.638	 backward Loss:12.0986;13.1926	 Sentiment Loss:0.1314	Valence Loss:0.7456	 Arousal Loss:1.9724	
[2025-11-07 06:56:38,904][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[460/968.0]	 Loss Sum:29.6346	forward Loss:3.0552;8.435	 backward Loss:12.2279;4.1799	 Sentiment Loss:0.3707	Valence Loss:5.0894	 Arousal Loss:1.74	
[2025-11-07 06:56:42,096][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[470/968.0]	 Loss Sum:28.7906	forward Loss:1.4598;14.0886	 backward Loss:8.7249;2.2135	 Sentiment Loss:1.6759	Valence Loss:1.5185	 Arousal Loss:1.6208	
[2025-11-07 06:56:45,050][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[480/968.0]	 Loss Sum:53.4665	forward Loss:6.1003;21.5661	 backward Loss:19.9417;4.1302	 Sentiment Loss:0.287	Valence Loss:4.3096	 Arousal Loss:2.8964	
[2025-11-07 06:56:48,025][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[490/968.0]	 Loss Sum:45.6867	forward Loss:14.4559;8.2862	 backward Loss:11.9316;9.7782	 Sentiment Loss:0.1788	Valence Loss:2.3861	 Arousal Loss:2.8942	
[2025-11-07 06:56:50,917][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[500/968.0]	 Loss Sum:29.5902	forward Loss:5.5013;9.3517	 backward Loss:6.8913;6.1475	 Sentiment Loss:1.1183	Valence Loss:1.5998	 Arousal Loss:1.3004	
[2025-11-07 06:56:53,827][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[510/968.0]	 Loss Sum:46.4255	forward Loss:10.2707;12.7636	 backward Loss:16.2362;5.7659	 Sentiment Loss:0.1578	Valence Loss:2.8274	 Arousal Loss:3.3284	
[2025-11-07 06:56:56,718][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[520/968.0]	 Loss Sum:65.7784	forward Loss:20.2543;11.1593	 backward Loss:12.7364;17.8994	 Sentiment Loss:2.7832	Valence Loss:2.4028	 Arousal Loss:2.3263	
[2025-11-07 06:56:59,688][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[530/968.0]	 Loss Sum:31.0803	forward Loss:11.3048;5.6802	 backward Loss:4.0196;9.3429	 Sentiment Loss:0.0901	Valence Loss:1.6596	 Arousal Loss:1.5535	
[2025-11-07 06:57:02,580][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[540/968.0]	 Loss Sum:33.6873	forward Loss:2.3801;6.9573	 backward Loss:5.702;4.5189	 Sentiment Loss:12.6556	Valence Loss:2.5325	 Arousal Loss:4.8347	
[2025-11-07 06:57:05,683][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[550/968.0]	 Loss Sum:25.8137	forward Loss:8.4497;3.944	 backward Loss:4.0562;6.8278	 Sentiment Loss:2.0307	Valence Loss:1.4315	 Arousal Loss:1.0951	
[2025-11-07 06:57:08,658][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[560/968.0]	 Loss Sum:46.9324	forward Loss:6.5485;10.4806	 backward Loss:21.4526;6.3476	 Sentiment Loss:1.5737	Valence Loss:1.0949	 Arousal Loss:1.5515	
[2025-11-07 06:57:11,686][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[570/968.0]	 Loss Sum:25.5975	forward Loss:2.4497;6.6522	 backward Loss:3.9691;9.36	 Sentiment Loss:2.239	Valence Loss:2.0089	 Arousal Loss:2.6291	
[2025-11-07 06:57:14,585][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[580/968.0]	 Loss Sum:37.7148	forward Loss:2.6848;14.1259	 backward Loss:12.0905;3.6656	 Sentiment Loss:4.4873	Valence Loss:1.8575	 Arousal Loss:1.4458	
[2025-11-07 06:57:17,489][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[590/968.0]	 Loss Sum:18.222	forward Loss:1.5751;6.2523	 backward Loss:4.3572;2.3527	 Sentiment Loss:2.8812	Valence Loss:1.8095	 Arousal Loss:2.2077	
[2025-11-07 06:57:20,449][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[600/968.0]	 Loss Sum:28.7541	forward Loss:11.0674;3.0993	 backward Loss:2.7892;10.6555	 Sentiment Loss:0.1495	Valence Loss:2.3284	 Arousal Loss:2.6374	
[2025-11-07 06:57:23,361][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[610/968.0]	 Loss Sum:54.5039	forward Loss:14.6137;11.8818	 backward Loss:10.4457;12.9419	 Sentiment Loss:4.2115	Valence Loss:1.1159	 Arousal Loss:0.93	
[2025-11-07 06:57:26,250][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[620/968.0]	 Loss Sum:21.5357	forward Loss:2.1934;7.1518	 backward Loss:7.9988;2.015	 Sentiment Loss:0.9447	Valence Loss:4.0536	 Arousal Loss:2.1064	
[2025-11-07 06:57:29,311][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[630/968.0]	 Loss Sum:63.6781	forward Loss:16.2892;10.7131	 backward Loss:10.116;20.5768	 Sentiment Loss:4.4005	Valence Loss:6.2867	 Arousal Loss:1.6266	
[2025-11-07 06:57:32,114][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[640/968.0]	 Loss Sum:18.1613	forward Loss:0.7663;7.581	 backward Loss:5.5355;1.16	 Sentiment Loss:2.4509	Valence Loss:1.5786	 Arousal Loss:1.7595	
[2025-11-07 06:57:35,314][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[650/968.0]	 Loss Sum:26.1506	forward Loss:6.3007;8.262	 backward Loss:5.0724;5.3915	 Sentiment Loss:0.5269	Valence Loss:1.2009	 Arousal Loss:1.785	
[2025-11-07 06:57:38,271][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[660/968.0]	 Loss Sum:31.5684	forward Loss:6.6143;9.4242	 backward Loss:5.4232;9.2098	 Sentiment Loss:0.5002	Valence Loss:0.8034	 Arousal Loss:1.1798	
[2025-11-07 06:57:41,246][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[670/968.0]	 Loss Sum:24.3941	forward Loss:2.5137;9.0678	 backward Loss:8.7211;2.0241	 Sentiment Loss:1.22	Valence Loss:3.5129	 Arousal Loss:0.7239	
[2025-11-07 06:57:44,142][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[680/968.0]	 Loss Sum:33.0467	forward Loss:7.3592;10.3738	 backward Loss:6.6943;7.0178	 Sentiment Loss:0.4885	Valence Loss:3.2094	 Arousal Loss:2.356	
[2025-11-07 06:57:47,048][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[690/968.0]	 Loss Sum:12.0769	forward Loss:2.8435;2.7222	 backward Loss:3.365;1.868	 Sentiment Loss:0.2787	Valence Loss:2.249	 Arousal Loss:2.7482	
[2025-11-07 06:57:49,944][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[700/968.0]	 Loss Sum:49.8311	forward Loss:14.8897;6.1806	 backward Loss:2.4679;25.0889	 Sentiment Loss:0.6787	Valence Loss:0.7386	 Arousal Loss:1.8884	
[2025-11-07 06:57:52,914][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[710/968.0]	 Loss Sum:32.4834	forward Loss:8.4395;11.1512	 backward Loss:9.6674;2.6705	 Sentiment Loss:0.1225	Valence Loss:1.145	 Arousal Loss:1.0164	
[2025-11-07 06:57:55,805][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[720/968.0]	 Loss Sum:26.5728	forward Loss:4.2625;4.9897	 backward Loss:2.2503;12.6819	 Sentiment Loss:1.7813	Valence Loss:1.7851	 Arousal Loss:1.2502	
[2025-11-07 06:57:58,880][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[730/968.0]	 Loss Sum:25.3149	forward Loss:3.422;9.6888	 backward Loss:5.3168;5.07	 Sentiment Loss:1.1199	Valence Loss:1.6294	 Arousal Loss:1.8577	
[2025-11-07 06:58:01,893][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[740/968.0]	 Loss Sum:31.0105	forward Loss:7.9888;9.7803	 backward Loss:5.3929;6.7592	 Sentiment Loss:0.5219	Valence Loss:1.196	 Arousal Loss:1.6408	
[2025-11-07 06:58:04,920][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[750/968.0]	 Loss Sum:30.025	forward Loss:11.3282;4.2017	 backward Loss:2.4306;10.6786	 Sentiment Loss:0.5283	Valence Loss:1.1886	 Arousal Loss:3.0997	
[2025-11-07 06:58:07,822][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[760/968.0]	 Loss Sum:60.5886	forward Loss:19.0643;9.0212	 backward Loss:9.029;19.4837	 Sentiment Loss:3.2418	Valence Loss:1.0646	 Arousal Loss:2.678	
[2025-11-07 06:58:10,730][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[770/968.0]	 Loss Sum:47.68	forward Loss:16.1165;9.3009	 backward Loss:4.0393;15.9795	 Sentiment Loss:0.6549	Valence Loss:3.7969	 Arousal Loss:4.1475	
[2025-11-07 06:58:13,701][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[780/968.0]	 Loss Sum:29.4497	forward Loss:5.3362;7.9696	 backward Loss:8.4456;6.0418	 Sentiment Loss:1.0193	Valence Loss:1.5783	 Arousal Loss:1.608	
[2025-11-07 06:58:16,608][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[790/968.0]	 Loss Sum:28.9141	forward Loss:5.5442;5.7472	 backward Loss:6.0992;10.7557	 Sentiment Loss:0.388	Valence Loss:0.4315	 Arousal Loss:1.4678	
[2025-11-07 06:58:19,498][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[800/968.0]	 Loss Sum:20.2571	forward Loss:2.0369;6.9745	 backward Loss:6.3404;1.1681	 Sentiment Loss:3.5026	Valence Loss:0.6418	 Arousal Loss:0.5313	
[2025-11-07 06:58:22,569][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[810/968.0]	 Loss Sum:33.862	forward Loss:6.8342;8.7545	 backward Loss:10.3476;6.4781	 Sentiment Loss:0.9666	Valence Loss:1.7434	 Arousal Loss:0.6618	
[2025-11-07 06:58:25,367][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[820/968.0]	 Loss Sum:21.0738	forward Loss:4.5164;4.5921	 backward Loss:7.803;2.0652	 Sentiment Loss:1.4642	Valence Loss:1.3887	 Arousal Loss:1.7757	
[2025-11-07 06:58:28,537][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[830/968.0]	 Loss Sum:60.9318	forward Loss:20.9145;10.4757	 backward Loss:9.6559;18.8618	 Sentiment Loss:0.344	Valence Loss:1.9048	 Arousal Loss:1.494	
[2025-11-07 06:58:31,518][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[840/968.0]	 Loss Sum:21.0412	forward Loss:5.6304;6.8128	 backward Loss:5.0828;2.9974	 Sentiment Loss:0.2015	Valence Loss:0.7216	 Arousal Loss:0.8597	
[2025-11-07 06:58:34,495][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[850/968.0]	 Loss Sum:13.9676	forward Loss:1.4706;5.0306	 backward Loss:4.4697;1.4229	 Sentiment Loss:0.8595	Valence Loss:2.3144	 Arousal Loss:1.2572	
[2025-11-07 06:58:37,391][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[860/968.0]	 Loss Sum:45.4664	forward Loss:8.0793;13.2137	 backward Loss:10.9419;11.9914	 Sentiment Loss:0.6578	Valence Loss:2.2861	 Arousal Loss:0.6253	
[2025-11-07 06:58:40,305][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[870/968.0]	 Loss Sum:67.0855	forward Loss:10.4063;25.61	 backward Loss:22.6769;7.1122	 Sentiment Loss:0.4943	Valence Loss:2.5366	 Arousal Loss:1.3918	
[2025-11-07 06:58:43,200][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[880/968.0]	 Loss Sum:21.6627	forward Loss:3.2933;10.6618	 backward Loss:3.6456;3.1279	 Sentiment Loss:0.1213	Valence Loss:3.305	 Arousal Loss:0.7596	
[2025-11-07 06:58:46,166][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[890/968.0]	 Loss Sum:36.0925	forward Loss:4.4265;9.5138	 backward Loss:12.1758;5.3427	 Sentiment Loss:3.9529	Valence Loss:1.5158	 Arousal Loss:1.8881	
[2025-11-07 06:58:49,053][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[900/968.0]	 Loss Sum:32.1243	forward Loss:12.1509;2.643	 backward Loss:2.5619;12.9507	 Sentiment Loss:1.4622	Valence Loss:0.4314	 Arousal Loss:1.3463	
[2025-11-07 06:58:52,117][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[910/968.0]	 Loss Sum:48.7015	forward Loss:11.0204;13.5227	 backward Loss:9.3121;12.1218	 Sentiment Loss:2.2348	Valence Loss:1.3542	 Arousal Loss:1.0943	
[2025-11-07 06:58:55,146][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[920/968.0]	 Loss Sum:32.6466	forward Loss:10.3017;7.1176	 backward Loss:7.2954;6.6032	 Sentiment Loss:0.2478	Valence Loss:2.8377	 Arousal Loss:2.5666	
[2025-11-07 06:58:58,173][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[930/968.0]	 Loss Sum:22.1136	forward Loss:4.1677;4.5676	 backward Loss:3.9315;7.29	 Sentiment Loss:0.9879	Valence Loss:3.9474	 Arousal Loss:1.8975	
[2025-11-07 06:59:01,078][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[940/968.0]	 Loss Sum:20.586	forward Loss:3.9205;3.6908	 backward Loss:3.5826;6.4759	 Sentiment Loss:2.4221	Valence Loss:1.3437	 Arousal Loss:1.1269	
[2025-11-07 06:59:03,991][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[950/968.0]	 Loss Sum:20.7921	forward Loss:3.1531;5.5905	 backward Loss:8.4462;2.4332	 Sentiment Loss:0.7369	Valence Loss:1.0797	 Arousal Loss:1.0815	
[2025-11-07 06:59:06,959][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[960/968.0]	 Loss Sum:14.6781	forward Loss:1.9743;6.3698	 backward Loss:3.6732;1.7358	 Sentiment Loss:0.3556	Valence Loss:2.2309	 Arousal Loss:0.616	
[2025-11-07 06:59:09,332][run_task2&3_trainer_multilingual.py][line:1126][INFO] dev
[2025-11-07 06:59:49,078][run_task2&3_trainer_multilingual.py][line:467][INFO] Triplet - Precision: 0.6401345287891622	Recall: 0.6701877930339273	F1: 0.6548160136494061
[2025-11-07 06:59:49,078][run_task2&3_trainer_multilingual.py][line:472][INFO] Aspect - Precision: 0.8625429547336474	Recall: 0.842281878629341	F1: 0.8522915198656229
[2025-11-07 06:59:49,078][run_task2&3_trainer_multilingual.py][line:477][INFO] Opinion - Precision: 0.8254568362788551	Recall: 0.7992678457600562	F1: 0.8121507705504604
[2025-11-07 06:59:49,078][run_task2&3_trainer_multilingual.py][line:483][INFO] Aspect-Category - Precision: 0.8032128508679967	Recall: 0.7905138334713347	F1: 0.7968122485069512
[2025-11-07 06:59:49,078][run_task2&3_trainer_multilingual.py][line:491][INFO] Aspect-Opinion - Precision: 0.6788116588123253	Recall: 0.7106807507566427	F1: 0.6943802338101847
[2025-11-07 06:59:49,079][run_task2&3_trainer_multilingual.py][line:1132][INFO] Model saved after epoch 1
[2025-11-07 06:59:50,028][run_task2&3_trainer_multilingual.py][line:1139][INFO] loading model......
[2025-11-07 06:59:50,782][run_task2&3_trainer_multilingual.py][line:1142][INFO] inference......
