[2025-11-12 02:30:25,193][_client.py][line:1025][INFO] HTTP Request: HEAD https://huggingface.co/bert-base-chinese/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
[2025-11-12 02:30:25,420][_client.py][line:1025][INFO] HTTP Request: GET https://huggingface.co/api/models/bert-base-chinese/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 307 Temporary Redirect"
[2025-11-12 02:30:25,609][_client.py][line:1025][INFO] HTTP Request: GET https://huggingface.co/api/models/google-bert/bert-base-chinese/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
[2025-11-12 02:30:25,823][_client.py][line:1025][INFO] HTTP Request: HEAD https://huggingface.co/bert-base-chinese/resolve/main/config.json "HTTP/1.1 200 OK"
[2025-11-12 02:30:26,021][_client.py][line:1025][INFO] HTTP Request: HEAD https://huggingface.co/bert-base-chinese/resolve/main/model.safetensors "HTTP/1.1 302 Found"
[2025-11-12 02:30:26,415][run_task2&3_trainer_multilingual.py][line:957][INFO] initial optimizer......
[2025-11-12 02:30:26,415][run_task2&3_trainer_multilingual.py][line:975][INFO] New model and optimizer from epoch 1
[2025-11-12 02:30:26,415][run_task2&3_trainer_multilingual.py][line:984][INFO] begin training......
[2025-11-12 02:30:30,113][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[10/2792.0]	 Loss Sum:118.2047	forward Loss:32.9895;22.8381	 backward Loss:19.9753;24.4899	 Sentiment Loss:5.3712	Valence Loss:35.02	 Arousal Loss:27.6836	
[2025-11-12 02:30:33,642][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[20/2792.0]	 Loss Sum:83.8416	forward Loss:18.8352;16.785	 backward Loss:14.1403;16.3838	 Sentiment Loss:5.8823	Valence Loss:38.1484	 Arousal Loss:20.9268	
[2025-11-12 02:30:37,167][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[30/2792.0]	 Loss Sum:143.7449	forward Loss:41.0568;26.6061	 backward Loss:22.8575;36.93	 Sentiment Loss:4.6022	Valence Loss:34.6271	 Arousal Loss:23.8346	
[2025-11-12 02:30:40,709][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[40/2792.0]	 Loss Sum:114.5475	forward Loss:28.3153;24.5769	 backward Loss:19.0463;28.4306	 Sentiment Loss:5.2898	Valence Loss:25.389	 Arousal Loss:19.054	
[2025-11-12 02:30:44,235][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[50/2792.0]	 Loss Sum:45.1128	forward Loss:9.2561;9.2358	 backward Loss:7.6495;9.6109	 Sentiment Loss:3.2297	Valence Loss:20.8364	 Arousal Loss:9.8178	
[2025-11-12 02:30:47,760][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[60/2792.0]	 Loss Sum:63.5843	forward Loss:11.6011;12.7986	 backward Loss:16.4793;10.7133	 Sentiment Loss:6.2973	Valence Loss:17.1834	 Arousal Loss:11.2909	
[2025-11-12 02:30:51,313][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[70/2792.0]	 Loss Sum:63.0569	forward Loss:18.1054;11.3518	 backward Loss:16.8464;12.182	 Sentiment Loss:2.6127	Valence Loss:7.4962	 Arousal Loss:2.297	
[2025-11-12 02:30:54,846][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[80/2792.0]	 Loss Sum:38.4725	forward Loss:7.9501;8.877	 backward Loss:7.2234;8.9343	 Sentiment Loss:2.2835	Valence Loss:9.2927	 Arousal Loss:6.7277	
[2025-11-12 02:30:58,388][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[90/2792.0]	 Loss Sum:69.9934	forward Loss:19.9939;11.3221	 backward Loss:22.8456;11.2069	 Sentiment Loss:3.3485	Valence Loss:5.91	 Arousal Loss:0.4724	
[2025-11-12 02:31:01,918][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[100/2792.0]	 Loss Sum:63.5698	forward Loss:16.0635;11.671	 backward Loss:19.2335;12.0013	 Sentiment Loss:4.3369	Valence Loss:1.2691	 Arousal Loss:0.0494	
[2025-11-12 02:31:05,443][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[110/2792.0]	 Loss Sum:38.5651	forward Loss:12.7852;7.6218	 backward Loss:7.2173;6.9062	 Sentiment Loss:2.8807	Valence Loss:4.3045	 Arousal Loss:1.4646	
[2025-11-12 02:31:08,979][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[120/2792.0]	 Loss Sum:34.041	forward Loss:7.02;8.7997	 backward Loss:7.4199;9.1126	 Sentiment Loss:1.1473	Valence Loss:0.5691	 Arousal Loss:2.1383	
[2025-11-12 02:31:12,513][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[130/2792.0]	 Loss Sum:26.6217	forward Loss:4.8041;7.1886	 backward Loss:6.464;5.9416	 Sentiment Loss:2.1787	Valence Loss:0.1734	 Arousal Loss:0.05	
[2025-11-12 02:31:16,058][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[140/2792.0]	 Loss Sum:41.3746	forward Loss:9.1324;10.1537	 backward Loss:8.733;10.1758	 Sentiment Loss:2.3793	Valence Loss:3.7723	 Arousal Loss:0.2295	
[2025-11-12 02:31:19,611][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[150/2792.0]	 Loss Sum:40.423	forward Loss:8.7886;11.0315	 backward Loss:9.6788;8.8874	 Sentiment Loss:1.952	Valence Loss:0.3872	 Arousal Loss:0.0369	
[2025-11-12 02:31:23,162][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[160/2792.0]	 Loss Sum:24.2412	forward Loss:4.0938;6.9796	 backward Loss:6.3405;5.0067	 Sentiment Loss:1.786	Valence Loss:0.0656	 Arousal Loss:0.1072	
[2025-11-12 02:31:26,707][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[170/2792.0]	 Loss Sum:21.6331	forward Loss:4.872;4.303	 backward Loss:3.8069;5.2483	 Sentiment Loss:2.9039	Valence Loss:1.2692	 Arousal Loss:1.225	
[2025-11-12 02:31:30,248][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[180/2792.0]	 Loss Sum:40.8674	forward Loss:14.5576;6.5529	 backward Loss:10.5076;6.4146	 Sentiment Loss:2.3322	Valence Loss:2.0392	 Arousal Loss:0.4735	
[2025-11-12 02:31:33,794][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[190/2792.0]	 Loss Sum:34.4737	forward Loss:6.9256;8.3245	 backward Loss:10.8202;4.6912	 Sentiment Loss:3.4409	Valence Loss:0.6591	 Arousal Loss:0.6973	
[2025-11-12 02:31:37,348][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[200/2792.0]	 Loss Sum:102.5572	forward Loss:28.2109;19.6438	 backward Loss:32.7663;15.5702	 Sentiment Loss:6.0452	Valence Loss:1.2472	 Arousal Loss:0.357	
[2025-11-12 02:31:40,907][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[210/2792.0]	 Loss Sum:34.2297	forward Loss:6.1538;7.6117	 backward Loss:11.6523;6.3604	 Sentiment Loss:2.4171	Valence Loss:0.0543	 Arousal Loss:0.1168	
[2025-11-12 02:31:44,458][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[220/2792.0]	 Loss Sum:26.1831	forward Loss:2.9772;7.5328	 backward Loss:8.1333;4.9061	 Sentiment Loss:2.3393	Valence Loss:0.3658	 Arousal Loss:1.1066	
[2025-11-12 02:31:48,013][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[230/2792.0]	 Loss Sum:31.2504	forward Loss:7.9769;4.1888	 backward Loss:5.0888;10.8113	 Sentiment Loss:3.1501	Valence Loss:0.0398	 Arousal Loss:0.1328	
[2025-11-12 02:31:51,564][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[240/2792.0]	 Loss Sum:19.5331	forward Loss:3.1515;5.2743	 backward Loss:4.5249;3.7618	 Sentiment Loss:2.0127	Valence Loss:3.733	 Arousal Loss:0.3069	
[2025-11-12 02:31:55,121][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[250/2792.0]	 Loss Sum:20.1396	forward Loss:2.8099;4.1623	 backward Loss:5.4986;3.7728	 Sentiment Loss:3.7611	Valence Loss:0.5966	 Arousal Loss:0.0777	
[2025-11-12 02:31:58,678][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[260/2792.0]	 Loss Sum:20.178	forward Loss:3.8851;2.9705	 backward Loss:3.6948;4.8116	 Sentiment Loss:4.6882	Valence Loss:0.5799	 Arousal Loss:0.0588	
[2025-11-12 02:32:02,239][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[270/2792.0]	 Loss Sum:24.2225	forward Loss:5.1425;3.5516	 backward Loss:4.1368;6.7623	 Sentiment Loss:3.7908	Valence Loss:1.1846	 Arousal Loss:3.0073	
[2025-11-12 02:32:05,792][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[280/2792.0]	 Loss Sum:24.4868	forward Loss:5.2643;2.5748	 backward Loss:2.1699;3.7317	 Sentiment Loss:10.7029	Valence Loss:0.0571	 Arousal Loss:0.1592	
[2025-11-12 02:32:09,355][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[290/2792.0]	 Loss Sum:10.1868	forward Loss:1.769;2.4476	 backward Loss:3.4678;1.7227	 Sentiment Loss:0.4963	Valence Loss:0.8081	 Arousal Loss:0.6095	
[2025-11-12 02:32:12,924][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[300/2792.0]	 Loss Sum:23.0638	forward Loss:4.2335;6.0714	 backward Loss:6.9698;4.3794	 Sentiment Loss:1.099	Valence Loss:0.0847	 Arousal Loss:1.4687	
[2025-11-12 02:32:16,491][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[310/2792.0]	 Loss Sum:24.9939	forward Loss:4.2947;6.7723	 backward Loss:6.387;3.6667	 Sentiment Loss:3.4199	Valence Loss:1.2095	 Arousal Loss:1.0568	
[2025-11-12 02:32:20,050][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[320/2792.0]	 Loss Sum:9.5147	forward Loss:1.6297;2.0834	 backward Loss:1.438;1.6728	 Sentiment Loss:2.6689	Valence Loss:0.0384	 Arousal Loss:0.071	
[2025-11-12 02:32:23,602][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[330/2792.0]	 Loss Sum:15.8713	forward Loss:2.6081;2.7076	 backward Loss:2.1629;3.3398	 Sentiment Loss:4.8421	Valence Loss:1.0032	 Arousal Loss:0.0503	
[2025-11-12 02:32:27,151][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[340/2792.0]	 Loss Sum:9.3974	forward Loss:1.7869;1.3645	 backward Loss:1.4605;2.7134	 Sentiment Loss:1.6703	Valence Loss:1.2524	 Arousal Loss:0.7566	
[2025-11-12 02:32:30,708][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[350/2792.0]	 Loss Sum:25.174	forward Loss:5.3911;6.356	 backward Loss:7.2443;4.7184	 Sentiment Loss:1.2514	Valence Loss:0.9286	 Arousal Loss:0.1351	
[2025-11-12 02:32:34,265][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[360/2792.0]	 Loss Sum:21.1363	forward Loss:7.3923;3.4958	 backward Loss:3.8764;5.5057	 Sentiment Loss:0.7215	Valence Loss:0.3848	 Arousal Loss:0.3378	
[2025-11-12 02:32:37,829][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[370/2792.0]	 Loss Sum:16.3084	forward Loss:1.7928;6.0542	 backward Loss:5.4831;1.838	 Sentiment Loss:0.4181	Valence Loss:2.8045	 Arousal Loss:0.8071	
[2025-11-12 02:32:41,411][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[380/2792.0]	 Loss Sum:43.0156	forward Loss:1.9321;13.8337	 backward Loss:18.1916;2.3915	 Sentiment Loss:6.1848	Valence Loss:2.2583	 Arousal Loss:0.1513	
[2025-11-12 02:32:44,972][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[390/2792.0]	 Loss Sum:15.7291	forward Loss:2.5659;3.1058	 backward Loss:2.2052;2.9366	 Sentiment Loss:3.7636	Valence Loss:1.6706	 Arousal Loss:4.0895	
[2025-11-12 02:32:48,526][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[400/2792.0]	 Loss Sum:17.7239	forward Loss:2.8208;3.6558	 backward Loss:4.4878;3.4373	 Sentiment Loss:2.4972	Valence Loss:2.7204	 Arousal Loss:1.405	
[2025-11-12 02:32:52,083][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[410/2792.0]	 Loss Sum:29.6966	forward Loss:2.9072;10.1737	 backward Loss:10.2184;2.5794	 Sentiment Loss:3.563	Valence Loss:0.0572	 Arousal Loss:1.2174	
[2025-11-12 02:32:55,646][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[420/2792.0]	 Loss Sum:31.188	forward Loss:14.4884;5.3352	 backward Loss:3.596;5.6776	 Sentiment Loss:1.8794	Valence Loss:0.3642	 Arousal Loss:0.693	
[2025-11-12 02:32:59,215][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[430/2792.0]	 Loss Sum:15.7765	forward Loss:4.2938;3.543	 backward Loss:3.5773;3.1734	 Sentiment Loss:0.6457	Valence Loss:1.3104	 Arousal Loss:1.4068	
[2025-11-12 02:33:02,785][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[440/2792.0]	 Loss Sum:25.2235	forward Loss:4.829;3.0552	 backward Loss:5.2297;4.6048	 Sentiment Loss:7.1265	Valence Loss:1.3564	 Arousal Loss:0.5344	
[2025-11-12 02:33:06,350][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[450/2792.0]	 Loss Sum:28.7654	forward Loss:5.4241;8.8185	 backward Loss:7.7387;2.1006	 Sentiment Loss:3.724	Valence Loss:4.2933	 Arousal Loss:0.5046	
[2025-11-12 02:33:09,921][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[460/2792.0]	 Loss Sum:38.8674	forward Loss:15.6007;3.9359	 backward Loss:9.5693;6.3914	 Sentiment Loss:3.2945	Valence Loss:0.2307	 Arousal Loss:0.1477	
[2025-11-12 02:33:13,495][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[470/2792.0]	 Loss Sum:26.7074	forward Loss:5.1875;2.16	 backward Loss:5.8829;5.0727	 Sentiment Loss:8.0584	Valence Loss:0.0358	 Arousal Loss:1.6932	
[2025-11-12 02:33:17,059][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[480/2792.0]	 Loss Sum:14.4806	forward Loss:7.662;1.8978	 backward Loss:2.2063;1.4568	 Sentiment Loss:1.1487	Valence Loss:0.4647	 Arousal Loss:0.0803	
[2025-11-12 02:33:20,627][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[490/2792.0]	 Loss Sum:12.9792	forward Loss:0.9788;3.4185	 backward Loss:4.2144;1.6145	 Sentiment Loss:2.2808	Valence Loss:1.3224	 Arousal Loss:1.0391	
[2025-11-12 02:33:24,199][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[500/2792.0]	 Loss Sum:17.8304	forward Loss:2.7112;4.9173	 backward Loss:6.2694;1.9003	 Sentiment Loss:1.5264	Valence Loss:2.2911	 Arousal Loss:0.2388	
[2025-11-12 02:33:27,758][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[510/2792.0]	 Loss Sum:8.8082	forward Loss:2.1439;1.4814	 backward Loss:0.9447;2.1137	 Sentiment Loss:2.1137	Valence Loss:0.0265	 Arousal Loss:0.0277	
[2025-11-12 02:33:31,335][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[520/2792.0]	 Loss Sum:11.0261	forward Loss:0.9736;2.8318	 backward Loss:5.3889;1.1415	 Sentiment Loss:0.4722	Valence Loss:0.134	 Arousal Loss:0.9566	
[2025-11-12 02:33:34,915][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[530/2792.0]	 Loss Sum:13.0139	forward Loss:2.8621;3.1983	 backward Loss:4.0617;2.0697	 Sentiment Loss:0.7776	Valence Loss:0.0941	 Arousal Loss:0.128	
[2025-11-12 02:33:38,497][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[540/2792.0]	 Loss Sum:9.7644	forward Loss:0.6617;3.5504	 backward Loss:0.8428;3.3269	 Sentiment Loss:0.3446	Valence Loss:5.0894	 Arousal Loss:0.1011	
[2025-11-12 02:33:42,087][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[550/2792.0]	 Loss Sum:19.9628	forward Loss:4.6673;5.6136	 backward Loss:3.5552;4.9912	 Sentiment Loss:0.7874	Valence Loss:1.6383	 Arousal Loss:0.1013	
[2025-11-12 02:33:45,660][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[560/2792.0]	 Loss Sum:13.2805	forward Loss:1.4566;0.8502	 backward Loss:1.6395;1.5935	 Sentiment Loss:7.1933	Valence Loss:2.7123	 Arousal Loss:0.0243	
[2025-11-12 02:33:49,251][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[570/2792.0]	 Loss Sum:14.4345	forward Loss:2.0359;2.7097	 backward Loss:4.9801;2.1959	 Sentiment Loss:0.6988	Valence Loss:7.8368	 Arousal Loss:1.2341	
[2025-11-12 02:33:52,830][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[580/2792.0]	 Loss Sum:18.195	forward Loss:3.1991;4.0497	 backward Loss:3.8371;4.4715	 Sentiment Loss:2.5045	Valence Loss:0.0891	 Arousal Loss:0.5767	
[2025-11-12 02:33:56,400][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[590/2792.0]	 Loss Sum:12.6085	forward Loss:1.4053;5.3138	 backward Loss:3.4685;1.8096	 Sentiment Loss:0.3089	Valence Loss:1.3881	 Arousal Loss:0.1232	
[2025-11-12 02:33:59,977][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[600/2792.0]	 Loss Sum:28.1816	forward Loss:4.9111;5.5072	 backward Loss:14.8158;2.5101	 Sentiment Loss:0.3163	Valence Loss:0.5341	 Arousal Loss:0.0718	
[2025-11-12 02:34:03,556][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[610/2792.0]	 Loss Sum:10.0157	forward Loss:2.0461;1.0893	 backward Loss:1.172;1.8108	 Sentiment Loss:3.5391	Valence Loss:0.1606	 Arousal Loss:1.6312	
[2025-11-12 02:34:07,124][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[620/2792.0]	 Loss Sum:14.7229	forward Loss:3.0024;2.9041	 backward Loss:3.5724;3.8823	 Sentiment Loss:1.1058	Valence Loss:1.1615	 Arousal Loss:0.1182	
[2025-11-12 02:34:10,692][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[630/2792.0]	 Loss Sum:7.8199	forward Loss:0.5991;2.3421	 backward Loss:2.8191;1.8024	 Sentiment Loss:0.153	Valence Loss:0.2538	 Arousal Loss:0.2678	
[2025-11-12 02:34:14,261][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[640/2792.0]	 Loss Sum:4.4049	forward Loss:1.5756;1.0031	 backward Loss:0.9592;0.6886	 Sentiment Loss:0.0499	Valence Loss:0.1365	 Arousal Loss:0.506	
[2025-11-12 02:34:17,829][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[650/2792.0]	 Loss Sum:11.7686	forward Loss:3.6231;0.8707	 backward Loss:2.1378;1.0306	 Sentiment Loss:3.6255	Valence Loss:1.9002	 Arousal Loss:0.5041	
[2025-11-12 02:34:21,393][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[660/2792.0]	 Loss Sum:27.0194	forward Loss:4.7166;3.2825	 backward Loss:6.1582;1.5042	 Sentiment Loss:11.1977	Valence Loss:0.6055	 Arousal Loss:0.1955	
[2025-11-12 02:34:24,968][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[670/2792.0]	 Loss Sum:29.6999	forward Loss:2.6762;12.9671	 backward Loss:7.9451;2.7458	 Sentiment Loss:3.1117	Valence Loss:0.1216	 Arousal Loss:1.1482	
[2025-11-12 02:34:28,531][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[680/2792.0]	 Loss Sum:15.3819	forward Loss:2.6841;3.0647	 backward Loss:6.4453;1.8631	 Sentiment Loss:1.2268	Valence Loss:0.0988	 Arousal Loss:0.3912	
[2025-11-12 02:34:32,105][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[690/2792.0]	 Loss Sum:20.7864	forward Loss:8.187;1.1485	 backward Loss:1.4178;3.7736	 Sentiment Loss:6.1095	Valence Loss:0.7048	 Arousal Loss:0.0451	
[2025-11-12 02:34:35,693][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[700/2792.0]	 Loss Sum:23.9602	forward Loss:1.1906;5.517	 backward Loss:14.1196;2.5936	 Sentiment Loss:0.4232	Valence Loss:0.055	 Arousal Loss:0.5261	
[2025-11-12 02:34:39,267][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[710/2792.0]	 Loss Sum:8.9355	forward Loss:2.8647;1.6484	 backward Loss:1.5838;1.554	 Sentiment Loss:0.9865	Valence Loss:1.3058	 Arousal Loss:0.1849	
[2025-11-12 02:34:42,850][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[720/2792.0]	 Loss Sum:28.9086	forward Loss:1.7444;11.6624	 backward Loss:11.6771;0.9828	 Sentiment Loss:1.6017	Valence Loss:4.1809	 Arousal Loss:2.0202	
[2025-11-12 02:34:46,428][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[730/2792.0]	 Loss Sum:11.1544	forward Loss:1.6105;1.7402	 backward Loss:2.0773;1.9383	 Sentiment Loss:3.3281	Valence Loss:2.1638	 Arousal Loss:0.1366	
[2025-11-12 02:34:50,005][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[740/2792.0]	 Loss Sum:5.0916	forward Loss:1.805;0.7701	 backward Loss:0.7062;1.2768	 Sentiment Loss:0.29	Valence Loss:0.6352	 Arousal Loss:0.5823	
[2025-11-12 02:34:53,585][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[750/2792.0]	 Loss Sum:8.6558	forward Loss:1.0649;1.6479	 backward Loss:2.0326;1.0157	 Sentiment Loss:2.6218	Valence Loss:1.0933	 Arousal Loss:0.2711	
[2025-11-12 02:34:57,162][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[760/2792.0]	 Loss Sum:31.4831	forward Loss:16.7944;1.594	 backward Loss:9.9723;2.5764	 Sentiment Loss:0.44	Valence Loss:0.2877	 Arousal Loss:0.2426	
[2025-11-12 02:35:00,745][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[770/2792.0]	 Loss Sum:6.3132	forward Loss:0.4465;3.0387	 backward Loss:0.9964;0.9809	 Sentiment Loss:0.3144	Valence Loss:1.0496	 Arousal Loss:1.6318	
[2025-11-12 02:35:04,322][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[780/2792.0]	 Loss Sum:29.0014	forward Loss:7.3414;2.8954	 backward Loss:9.7856;5.2118	 Sentiment Loss:2.9568	Valence Loss:3.2184	 Arousal Loss:0.8333	
[2025-11-12 02:35:07,910][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[790/2792.0]	 Loss Sum:20.4776	forward Loss:2.2447;6.8602	 backward Loss:4.5779;3.6103	 Sentiment Loss:2.8749	Valence Loss:0.762	 Arousal Loss:0.7867	
[2025-11-12 02:35:11,482][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[800/2792.0]	 Loss Sum:18.0799	forward Loss:0.4754;5.5398	 backward Loss:5.6175;1.0418	 Sentiment Loss:5.3139	Valence Loss:0.3458	 Arousal Loss:0.1118	
[2025-11-12 02:35:15,061][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[810/2792.0]	 Loss Sum:3.8219	forward Loss:0.3848;1.3639	 backward Loss:1.114;0.7074	 Sentiment Loss:0.1742	Valence Loss:0.3113	 Arousal Loss:0.0764	
[2025-11-12 02:35:18,637][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[820/2792.0]	 Loss Sum:18.6371	forward Loss:8.1933;3.2778	 backward Loss:3.7015;1.6014	 Sentiment Loss:1.5358	Valence Loss:0.9952	 Arousal Loss:0.6417	
[2025-11-12 02:35:22,203][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[830/2792.0]	 Loss Sum:35.8924	forward Loss:4.9771;11.9834	 backward Loss:11.9783;1.8657	 Sentiment Loss:4.5998	Valence Loss:2.3797	 Arousal Loss:0.0607	
[2025-11-12 02:35:25,776][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[840/2792.0]	 Loss Sum:28.0829	forward Loss:7.5244;3.3545	 backward Loss:13.1809;3.3384	 Sentiment Loss:0.5552	Valence Loss:0.4641	 Arousal Loss:0.1834	
[2025-11-12 02:35:29,350][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[850/2792.0]	 Loss Sum:20.5344	forward Loss:5.17;4.775	 backward Loss:6.9782;1.9832	 Sentiment Loss:1.3046	Valence Loss:1.5784	 Arousal Loss:0.0377	
[2025-11-12 02:35:32,917][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[860/2792.0]	 Loss Sum:16.7155	forward Loss:3.4362;2.6148	 backward Loss:6.3415;3.9318	 Sentiment Loss:0.0776	Valence Loss:1.0082	 Arousal Loss:0.5605	
[2025-11-12 02:35:36,490][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[870/2792.0]	 Loss Sum:9.5531	forward Loss:0.6942;0.6958	 backward Loss:6.2779;0.8166	 Sentiment Loss:0.8918	Valence Loss:0.5342	 Arousal Loss:0.35	
[2025-11-12 02:35:40,072][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[880/2792.0]	 Loss Sum:24.6716	forward Loss:5.7776;5.9122	 backward Loss:7.1105;4.3155	 Sentiment Loss:1.5317	Valence Loss:0.0918	 Arousal Loss:0.0283	
[2025-11-12 02:35:43,646][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[890/2792.0]	 Loss Sum:9.3939	forward Loss:2.8422;0.9707	 backward Loss:2.2276;2.58	 Sentiment Loss:0.342	Valence Loss:1.1948	 Arousal Loss:0.9625	
[2025-11-12 02:35:47,212][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[900/2792.0]	 Loss Sum:7.7405	forward Loss:1.8181;0.3527	 backward Loss:1.1449;0.8701	 Sentiment Loss:2.5406	Valence Loss:3.6907	 Arousal Loss:1.38	
[2025-11-12 02:35:50,781][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[910/2792.0]	 Loss Sum:19.0166	forward Loss:2.3207;2.3324	 backward Loss:10.9721;1.6511	 Sentiment Loss:1.5638	Valence Loss:0.4156	 Arousal Loss:0.4666	
[2025-11-12 02:35:54,348][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[920/2792.0]	 Loss Sum:6.1421	forward Loss:1.6196;0.5618	 backward Loss:2.5602;0.974	 Sentiment Loss:0.2465	Valence Loss:0.4016	 Arousal Loss:0.4982	
[2025-11-12 02:35:57,931][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[930/2792.0]	 Loss Sum:11.1356	forward Loss:0.8903;3.1455	 backward Loss:5.4814;1.466	 Sentiment Loss:0.0603	Valence Loss:0.2036	 Arousal Loss:0.2572	
[2025-11-12 02:36:01,498][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[940/2792.0]	 Loss Sum:10.2159	forward Loss:5.5009;0.4654	 backward Loss:0.4278;3.4225	 Sentiment Loss:0.3332	Valence Loss:0.2429	 Arousal Loss:0.0886	
[2025-11-12 02:36:05,079][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[950/2792.0]	 Loss Sum:20.5961	forward Loss:3.6445;4.6838	 backward Loss:6.8341;0.9426	 Sentiment Loss:3.1712	Valence Loss:6.129	 Arousal Loss:0.4708	
[2025-11-12 02:36:08,642][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[960/2792.0]	 Loss Sum:20.1808	forward Loss:2.8875;3.8092	 backward Loss:10.8261;2.5826	 Sentiment Loss:0.0434	Valence Loss:0.0788	 Arousal Loss:0.0811	
[2025-11-12 02:36:12,213][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[970/2792.0]	 Loss Sum:18.7786	forward Loss:2.8408;5.3	 backward Loss:8.1102;1.6137	 Sentiment Loss:0.7651	Valence Loss:0.6212	 Arousal Loss:0.1228	
[2025-11-12 02:36:15,784][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[980/2792.0]	 Loss Sum:18.2701	forward Loss:2.7538;2.1852	 backward Loss:3.949;1.7921	 Sentiment Loss:7.4714	Valence Loss:0.4587	 Arousal Loss:0.1341	
[2025-11-12 02:36:19,357][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[990/2792.0]	 Loss Sum:3.6448	forward Loss:1.3625;0.7284	 backward Loss:0.9254;0.2847	 Sentiment Loss:0.2064	Valence Loss:0.1463	 Arousal Loss:0.5397	
[2025-11-12 02:36:22,947][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1000/2792.0]	 Loss Sum:9.7295	forward Loss:1.2409;1.5974	 backward Loss:4.4542;1.8069	 Sentiment Loss:0.2961	Valence Loss:1.3262	 Arousal Loss:0.3435	
[2025-11-12 02:36:26,538][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1010/2792.0]	 Loss Sum:28.3092	forward Loss:1.2045;12.6732	 backward Loss:9.6843;0.4779	 Sentiment Loss:3.3787	Valence Loss:2.5796	 Arousal Loss:1.8739	
[2025-11-12 02:36:30,115][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1020/2792.0]	 Loss Sum:10.7692	forward Loss:0.5859;3.2061	 backward Loss:4.9227;1.0587	 Sentiment Loss:0.5437	Valence Loss:0.6555	 Arousal Loss:1.6051	
[2025-11-12 02:36:33,688][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1030/2792.0]	 Loss Sum:5.3043	forward Loss:0.923;0.7637	 backward Loss:2.2;1.0581	 Sentiment Loss:0.228	Valence Loss:0.2051	 Arousal Loss:0.4531	
[2025-11-12 02:36:37,282][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1040/2792.0]	 Loss Sum:22.9096	forward Loss:0.3809;7.2381	 backward Loss:6.5159;0.4557	 Sentiment Loss:8.0821	Valence Loss:0.2528	 Arousal Loss:0.932	
[2025-11-12 02:36:40,860][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1050/2792.0]	 Loss Sum:16.56	forward Loss:4.9291;3.7479	 backward Loss:5.7037;1.075	 Sentiment Loss:0.893	Valence Loss:0.5636	 Arousal Loss:0.493	
[2025-11-12 02:36:44,433][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1060/2792.0]	 Loss Sum:7.0008	forward Loss:1.1548;1.5332	 backward Loss:1.8993;2.2707	 Sentiment Loss:0.064	Valence Loss:0.2926	 Arousal Loss:0.1013	
[2025-11-12 02:36:48,006][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1070/2792.0]	 Loss Sum:17.5035	forward Loss:5.8813;0.9361	 backward Loss:0.6833;2.6751	 Sentiment Loss:7.0806	Valence Loss:0.4557	 Arousal Loss:0.7802	
[2025-11-12 02:36:51,592][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1080/2792.0]	 Loss Sum:15.4469	forward Loss:3.895;2.4363	 backward Loss:3.6199;4.4257	 Sentiment Loss:1.0259	Valence Loss:0.1779	 Arousal Loss:0.0426	
[2025-11-12 02:36:55,163][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1090/2792.0]	 Loss Sum:23.4167	forward Loss:0.8459;4.8788	 backward Loss:14.2052;1.7378	 Sentiment Loss:1.5158	Valence Loss:1.136	 Arousal Loss:0.0301	
[2025-11-12 02:36:58,736][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1100/2792.0]	 Loss Sum:23.6313	forward Loss:2.9623;4.5472	 backward Loss:5.9417;2.1531	 Sentiment Loss:7.0937	Valence Loss:3.546	 Arousal Loss:1.1202	
[2025-11-12 02:37:02,312][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1110/2792.0]	 Loss Sum:27.4613	forward Loss:6.2146;7.3298	 backward Loss:8.7763;1.8447	 Sentiment Loss:3.1149	Valence Loss:0.8563	 Arousal Loss:0.0495	
[2025-11-12 02:37:05,884][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1120/2792.0]	 Loss Sum:15.8573	forward Loss:3.1903;1.995	 backward Loss:7.5852;2.6535	 Sentiment Loss:0.3341	Valence Loss:0.4381	 Arousal Loss:0.0578	
[2025-11-12 02:37:09,464][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1130/2792.0]	 Loss Sum:6.6341	forward Loss:0.4062;3.4247	 backward Loss:1.7031;0.8116	 Sentiment Loss:0.0544	Valence Loss:1.0004	 Arousal Loss:0.1699	
[2025-11-12 02:37:13,035][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1140/2792.0]	 Loss Sum:12.7432	forward Loss:1.7662;2.4409	 backward Loss:1.8724;3.8004	 Sentiment Loss:2.6561	Valence Loss:0.8999	 Arousal Loss:0.1365	
[2025-11-12 02:37:16,605][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1150/2792.0]	 Loss Sum:17.9195	forward Loss:7.2177;4.3095	 backward Loss:4.8701;1.4615	 Sentiment Loss:0.0214	Valence Loss:0.1185	 Arousal Loss:0.0781	
[2025-11-12 02:37:20,175][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1160/2792.0]	 Loss Sum:11.833	forward Loss:3.5789;1.8139	 backward Loss:2.7568;2.5347	 Sentiment Loss:1.038	Valence Loss:0.209	 Arousal Loss:0.3442	
[2025-11-12 02:37:23,743][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1170/2792.0]	 Loss Sum:5.3178	forward Loss:0.6731;2.2294	 backward Loss:0.8845;1.325	 Sentiment Loss:0.0834	Valence Loss:0.3537	 Arousal Loss:0.2579	
[2025-11-12 02:37:27,317][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1180/2792.0]	 Loss Sum:12.6567	forward Loss:5.3996;1.3182	 backward Loss:1.5094;4.1854	 Sentiment Loss:0.1514	Valence Loss:0.3903	 Arousal Loss:0.073	
[2025-11-12 02:37:30,887][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1190/2792.0]	 Loss Sum:35.887	forward Loss:12.3235;3.0964	 backward Loss:5.8472;12.6458	 Sentiment Loss:1.6374	Valence Loss:0.8778	 Arousal Loss:0.8052	
[2025-11-12 02:37:34,467][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1200/2792.0]	 Loss Sum:15.1792	forward Loss:3.6798;2.8781	 backward Loss:5.0364;2.3893	 Sentiment Loss:1.0383	Valence Loss:0.3786	 Arousal Loss:0.4078	
[2025-11-12 02:37:38,035][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1210/2792.0]	 Loss Sum:11.9264	forward Loss:3.312;1.637	 backward Loss:2.5486;3.7845	 Sentiment Loss:0.5113	Valence Loss:0.1621	 Arousal Loss:0.5034	
[2025-11-12 02:37:41,613][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1220/2792.0]	 Loss Sum:21.6119	forward Loss:6.633;1.8382	 backward Loss:7.0441;4.1925	 Sentiment Loss:1.4113	Valence Loss:2.385	 Arousal Loss:0.0789	
[2025-11-12 02:37:45,206][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1230/2792.0]	 Loss Sum:15.9156	forward Loss:5.4444;1.6486	 backward Loss:4.1467;3.952	 Sentiment Loss:0.5194	Valence Loss:0.1669	 Arousal Loss:0.8553	
[2025-11-12 02:37:48,769][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1240/2792.0]	 Loss Sum:11.9911	forward Loss:2.9711;2.6915	 backward Loss:1.9214;3.1773	 Sentiment Loss:1.0427	Valence Loss:0.0845	 Arousal Loss:0.851	
[2025-11-12 02:37:52,626][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1250/2792.0]	 Loss Sum:12.4855	forward Loss:5.0878;1.9228	 backward Loss:2.5846;1.3529	 Sentiment Loss:1.0315	Valence Loss:2.3094	 Arousal Loss:0.2203	
[2025-11-12 02:37:56,199][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1260/2792.0]	 Loss Sum:1.5313	forward Loss:0.412;0.2777	 backward Loss:0.2314;0.3131	 Sentiment Loss:0.1096	Valence Loss:0.7034	 Arousal Loss:0.2342	
[2025-11-12 02:37:59,769][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1270/2792.0]	 Loss Sum:10.5906	forward Loss:1.3184;3.4584	 backward Loss:3.4293;1.6632	 Sentiment Loss:0.6804	Valence Loss:0.1127	 Arousal Loss:0.0923	
[2025-11-12 02:38:03,341][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1280/2792.0]	 Loss Sum:11.3379	forward Loss:0.4149;4.1061	 backward Loss:5.3628;0.4949	 Sentiment Loss:0.8715	Valence Loss:0.1823	 Arousal Loss:0.2561	
[2025-11-12 02:38:06,915][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1290/2792.0]	 Loss Sum:12.684	forward Loss:3.6993;1.4839	 backward Loss:3.643;2.1454	 Sentiment Loss:1.6836	Valence Loss:0.0725	 Arousal Loss:0.0718	
[2025-11-12 02:38:10,501][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1300/2792.0]	 Loss Sum:59.0526	forward Loss:14.9452;12.2229	 backward Loss:16.3732;12.5034	 Sentiment Loss:2.3118	Valence Loss:2.1816	 Arousal Loss:1.2992	
[2025-11-12 02:38:14,079][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1310/2792.0]	 Loss Sum:13.878	forward Loss:3.9615;1.3697	 backward Loss:5.4919;2.812	 Sentiment Loss:0.1649	Valence Loss:0.1499	 Arousal Loss:0.2399	
[2025-11-12 02:38:17,657][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1320/2792.0]	 Loss Sum:23.8982	forward Loss:0.9294;5.5433	 backward Loss:11.7475;1.3914	 Sentiment Loss:4.2064	Valence Loss:0.0559	 Arousal Loss:0.3449	
[2025-11-12 02:38:21,248][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1330/2792.0]	 Loss Sum:7.4029	forward Loss:0.6127;2.592	 backward Loss:2.8152;0.8928	 Sentiment Loss:0.1836	Valence Loss:1.2084	 Arousal Loss:0.325	
[2025-11-12 02:38:24,821][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1340/2792.0]	 Loss Sum:10.2366	forward Loss:0.4112;4.5101	 backward Loss:4.3102;0.2445	 Sentiment Loss:0.014	Valence Loss:3.4815	 Arousal Loss:0.2517	
[2025-11-12 02:38:28,398][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1350/2792.0]	 Loss Sum:35.1586	forward Loss:0.836;12.8644	 backward Loss:15.0115;0.6301	 Sentiment Loss:5.4798	Valence Loss:1.5106	 Arousal Loss:0.1735	
[2025-11-12 02:38:31,984][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1360/2792.0]	 Loss Sum:27.552	forward Loss:4.6138;8.6146	 backward Loss:10.2614;2.8817	 Sentiment Loss:1.1528	Valence Loss:0.0542	 Arousal Loss:0.0848	
[2025-11-12 02:38:35,573][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1370/2792.0]	 Loss Sum:11.6182	forward Loss:0.4711;4.4333	 backward Loss:4.8344;1.2771	 Sentiment Loss:0.1135	Valence Loss:2.3629	 Arousal Loss:0.0811	
[2025-11-12 02:38:39,151][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1380/2792.0]	 Loss Sum:46.2479	forward Loss:15.4575;5.5945	 backward Loss:19.445;4.5419	 Sentiment Loss:0.8465	Valence Loss:0.0886	 Arousal Loss:1.724	
[2025-11-12 02:38:42,737][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1390/2792.0]	 Loss Sum:14.6183	forward Loss:2.6513;2.4134	 backward Loss:3.7902;2.2518	 Sentiment Loss:3.4624	Valence Loss:0.0905	 Arousal Loss:0.1554	
[2025-11-12 02:38:46,312][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1400/2792.0]	 Loss Sum:3.6886	forward Loss:1.0081;1.0061	 backward Loss:0.7623;0.7774	 Sentiment Loss:0.08	Valence Loss:0.0791	 Arousal Loss:0.194	
[2025-11-12 02:38:49,888][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1410/2792.0]	 Loss Sum:29.6721	forward Loss:7.5374;6.2645	 backward Loss:7.2396;4.1275	 Sentiment Loss:4.3895	Valence Loss:0.2904	 Arousal Loss:0.2778	
[2025-11-12 02:38:53,462][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1420/2792.0]	 Loss Sum:15.4122	forward Loss:6.6334;2.4282	 backward Loss:5.428;0.4456	 Sentiment Loss:0.0761	Valence Loss:1.5064	 Arousal Loss:0.498	
[2025-11-12 02:38:57,039][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1430/2792.0]	 Loss Sum:24.6876	forward Loss:2.872;5.2843	 backward Loss:6.5875;6.6183	 Sentiment Loss:3.0955	Valence Loss:0.7782	 Arousal Loss:0.3721	
[2025-11-12 02:39:00,615][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1440/2792.0]	 Loss Sum:10.4475	forward Loss:2.3454;1.1065	 backward Loss:2.1775;4.5618	 Sentiment Loss:0.1241	Valence Loss:0.1949	 Arousal Loss:0.466	
[2025-11-12 02:39:04,190][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1450/2792.0]	 Loss Sum:14.1106	forward Loss:4.435;2.0816	 backward Loss:3.1969;3.8925	 Sentiment Loss:0.3803	Valence Loss:0.5459	 Arousal Loss:0.0759	
[2025-11-12 02:39:07,772][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1460/2792.0]	 Loss Sum:5.5457	forward Loss:0.703;1.9854	 backward Loss:1.6479;1.0236	 Sentiment Loss:0.123	Valence Loss:0.1576	 Arousal Loss:0.1558	
[2025-11-12 02:39:11,348][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1470/2792.0]	 Loss Sum:2.309	forward Loss:0.1534;0.6299	 backward Loss:0.472;0.8978	 Sentiment Loss:0.0067	Valence Loss:0.6301	 Arousal Loss:0.1159	
[2025-11-12 02:39:14,929][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1480/2792.0]	 Loss Sum:21.0291	forward Loss:0.6349;7.7998	 backward Loss:5.5067;0.4346	 Sentiment Loss:6.3909	Valence Loss:1.0668	 Arousal Loss:0.2448	
[2025-11-12 02:39:18,507][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1490/2792.0]	 Loss Sum:14.3146	forward Loss:4.5862;1.1666	 backward Loss:4.8312;2.8593	 Sentiment Loss:0.7999	Valence Loss:0.292	 Arousal Loss:0.065	
[2025-11-12 02:39:22,074][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1500/2792.0]	 Loss Sum:10.5656	forward Loss:0.2785;4.7565	 backward Loss:4.8537;0.5	 Sentiment Loss:0.0391	Valence Loss:0.5335	 Arousal Loss:0.1555	
[2025-11-12 02:39:25,658][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1510/2792.0]	 Loss Sum:21.7712	forward Loss:1.0497;8.8414	 backward Loss:5.7747;1.9701	 Sentiment Loss:3.6887	Valence Loss:2.1731	 Arousal Loss:0.0595	
[2025-11-12 02:39:29,235][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1520/2792.0]	 Loss Sum:8.3987	forward Loss:1.381;1.4241	 backward Loss:1.738;1.7635	 Sentiment Loss:2.0195	Valence Loss:0.2091	 Arousal Loss:0.1546	
[2025-11-12 02:39:32,813][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1530/2792.0]	 Loss Sum:20.8263	forward Loss:6.7489;4.0156	 backward Loss:5.2556;4.0554	 Sentiment Loss:0.6692	Valence Loss:0.2933	 Arousal Loss:0.1148	
[2025-11-12 02:39:36,395][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1540/2792.0]	 Loss Sum:9.306	forward Loss:1.2811;2.5036	 backward Loss:1.6484;2.0211	 Sentiment Loss:0.3829	Valence Loss:5.9043	 Arousal Loss:1.4404	
[2025-11-12 02:39:39,990][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1550/2792.0]	 Loss Sum:19.8973	forward Loss:3.8882;1.819	 backward Loss:9.3631;3.1096	 Sentiment Loss:1.6127	Valence Loss:0.3287	 Arousal Loss:0.1952	
[2025-11-12 02:39:43,564][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1560/2792.0]	 Loss Sum:3.6505	forward Loss:0.5852;0.7976	 backward Loss:1.6992;0.5308	 Sentiment Loss:0.0045	Valence Loss:0.0694	 Arousal Loss:0.0963	
[2025-11-12 02:39:47,137][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1570/2792.0]	 Loss Sum:14.3703	forward Loss:1.0355;2.2429	 backward Loss:3.8136;2.0757	 Sentiment Loss:4.7999	Valence Loss:1.1074	 Arousal Loss:0.9067	
[2025-11-12 02:39:50,709][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1580/2792.0]	 Loss Sum:11.006	forward Loss:0.3023;5.6676	 backward Loss:4.6603;0.3007	 Sentiment Loss:0.0288	Valence Loss:0.043	 Arousal Loss:0.1886	
[2025-11-12 02:39:54,281][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1590/2792.0]	 Loss Sum:19.9716	forward Loss:1.0074;9.7804	 backward Loss:7.0963;1.2313	 Sentiment Loss:0.7073	Valence Loss:0.3438	 Arousal Loss:0.4008	
[2025-11-12 02:39:57,865][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1600/2792.0]	 Loss Sum:20.5757	forward Loss:1.258;10.0335	 backward Loss:5.9184;2.3106	 Sentiment Loss:0.8439	Valence Loss:0.4796	 Arousal Loss:0.5772	
[2025-11-12 02:40:01,442][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1610/2792.0]	 Loss Sum:23.5445	forward Loss:2.7972;5.1756	 backward Loss:9.8644;2.4088	 Sentiment Loss:3.2456	Valence Loss:0.2306	 Arousal Loss:0.0341	
[2025-11-12 02:40:05,015][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1620/2792.0]	 Loss Sum:10.5248	forward Loss:1.9623;0.8387	 backward Loss:1.198;2.2747	 Sentiment Loss:4.224	Valence Loss:0.1044	 Arousal Loss:0.0314	
[2025-11-12 02:40:08,593][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1630/2792.0]	 Loss Sum:10.0622	forward Loss:4.2709;1.2665	 backward Loss:1.9494;2.048	 Sentiment Loss:0.2977	Valence Loss:0.8709	 Arousal Loss:0.2771	
[2025-11-12 02:40:12,157][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1640/2792.0]	 Loss Sum:3.328	forward Loss:0.8632;1.0434	 backward Loss:0.6947;0.432	 Sentiment Loss:0.0276	Valence Loss:0.645	 Arousal Loss:0.69	
[2025-11-12 02:40:15,735][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1650/2792.0]	 Loss Sum:35.9611	forward Loss:10.6485;6.8506	 backward Loss:15.24;2.522	 Sentiment Loss:0.1667	Valence Loss:1.5479	 Arousal Loss:1.1192	
[2025-11-12 02:40:19,303][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1660/2792.0]	 Loss Sum:14.5171	forward Loss:0.5763;8.6967	 backward Loss:4.237;0.4991	 Sentiment Loss:0.4132	Valence Loss:0.4263	 Arousal Loss:0.0481	
[2025-11-12 02:40:22,879][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1670/2792.0]	 Loss Sum:34.8608	forward Loss:8.4116;9.0543	 backward Loss:13.1677;3.8471	 Sentiment Loss:0.046	Valence Loss:1.6543	 Arousal Loss:0.0167	
[2025-11-12 02:40:26,455][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1680/2792.0]	 Loss Sum:21.5995	forward Loss:6.1912;4.4299	 backward Loss:5.8082;1.6811	 Sentiment Loss:2.9452	Valence Loss:2.5639	 Arousal Loss:0.1554	
[2025-11-12 02:40:30,026][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1690/2792.0]	 Loss Sum:8.3954	forward Loss:0.9971;2.1394	 backward Loss:3.3612;0.7401	 Sentiment Loss:1.1242	Valence Loss:0.1143	 Arousal Loss:0.0526	
[2025-11-12 02:40:33,590][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1700/2792.0]	 Loss Sum:41.4902	forward Loss:6.354;13.1687	 backward Loss:12.5478;4.9938	 Sentiment Loss:4.2549	Valence Loss:0.7136	 Arousal Loss:0.1417	
[2025-11-12 02:40:37,152][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1710/2792.0]	 Loss Sum:11.9938	forward Loss:4.6961;0.5091	 backward Loss:0.7184;3.2191	 Sentiment Loss:2.476	Valence Loss:0.4121	 Arousal Loss:1.4633	
[2025-11-12 02:40:40,723][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1720/2792.0]	 Loss Sum:6.168	forward Loss:1.0558;1.5489	 backward Loss:1.4118;1.4108	 Sentiment Loss:0.6919	Valence Loss:0.1468	 Arousal Loss:0.0968	
[2025-11-12 02:40:44,300][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1730/2792.0]	 Loss Sum:31.1129	forward Loss:2.6387;10.0285	 backward Loss:12.6869;4.9932	 Sentiment Loss:0.5113	Valence Loss:1.0411	 Arousal Loss:0.2308	
[2025-11-12 02:40:47,879][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1740/2792.0]	 Loss Sum:13.5671	forward Loss:1.4071;3.4503	 backward Loss:4.7324;1.91	 Sentiment Loss:1.8978	Valence Loss:0.4661	 Arousal Loss:0.3809	
[2025-11-12 02:40:51,465][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1750/2792.0]	 Loss Sum:21.1713	forward Loss:9.8675;3.4375	 backward Loss:2.592;4.8556	 Sentiment Loss:0.1594	Valence Loss:1.0905	 Arousal Loss:0.2058	
[2025-11-12 02:40:55,047][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1760/2792.0]	 Loss Sum:28.8808	forward Loss:11.9341;3.1765	 backward Loss:9.6035;2.7022	 Sentiment Loss:1.2109	Valence Loss:0.8872	 Arousal Loss:0.3809	
[2025-11-12 02:40:58,611][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1770/2792.0]	 Loss Sum:6.9909	forward Loss:3.4479;0.4049	 backward Loss:1.7938;0.8894	 Sentiment Loss:0.0106	Valence Loss:0.1519	 Arousal Loss:2.0697	
[2025-11-12 02:41:02,199][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1780/2792.0]	 Loss Sum:65.1768	forward Loss:17.5558;7.1417	 backward Loss:32.515;4.6886	 Sentiment Loss:3.0283	Valence Loss:0.4961	 Arousal Loss:0.7401	
[2025-11-12 02:41:05,778][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1790/2792.0]	 Loss Sum:5.1635	forward Loss:1.0292;1.0291	 backward Loss:1.0528;1.4455	 Sentiment Loss:0.3547	Valence Loss:0.3661	 Arousal Loss:0.8949	
[2025-11-12 02:41:09,359][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1800/2792.0]	 Loss Sum:21.4665	forward Loss:5.5464;4.1181	 backward Loss:8.5297;2.8439	 Sentiment Loss:0.236	Valence Loss:0.8306	 Arousal Loss:0.131	
[2025-11-12 02:41:12,939][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1810/2792.0]	 Loss Sum:23.8479	forward Loss:6.3813;2.1807	 backward Loss:2.1275;12.8967	 Sentiment Loss:0.0212	Valence Loss:1.1268	 Arousal Loss:0.0753	
[2025-11-12 02:41:16,529][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1820/2792.0]	 Loss Sum:34.9003	forward Loss:9.2409;3.5142	 backward Loss:12.1126;1.5452	 Sentiment Loss:8.4365	Valence Loss:0.0842	 Arousal Loss:0.1702	
[2025-11-12 02:41:20,125][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1830/2792.0]	 Loss Sum:42.1633	forward Loss:11.2653;6.4944	 backward Loss:10.1356;13.03	 Sentiment Loss:1.1551	Valence Loss:0.1648	 Arousal Loss:0.2497	
[2025-11-12 02:41:23,711][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1840/2792.0]	 Loss Sum:49.0406	forward Loss:6.1436;6.443	 backward Loss:27.6499;3.9457	 Sentiment Loss:4.4991	Valence Loss:1.2338	 Arousal Loss:0.5624	
[2025-11-12 02:41:27,292][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1850/2792.0]	 Loss Sum:39.0037	forward Loss:10.0021;7.2106	 backward Loss:6.1954;7.9757	 Sentiment Loss:7.5726	Valence Loss:0.1304	 Arousal Loss:0.1053	
[2025-11-12 02:41:30,863][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1860/2792.0]	 Loss Sum:11.8457	forward Loss:2.202;1.1266	 backward Loss:3.451;1.9119	 Sentiment Loss:3.0853	Valence Loss:0.2041	 Arousal Loss:0.1399	
[2025-11-12 02:41:34,445][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1870/2792.0]	 Loss Sum:9.7499	forward Loss:4.3493;0.7834	 backward Loss:1.116;3.1285	 Sentiment Loss:0.0556	Valence Loss:0.8547	 Arousal Loss:0.7302	
[2025-11-12 02:41:38,018][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1880/2792.0]	 Loss Sum:6.4597	forward Loss:0.3734;0.7383	 backward Loss:0.9069;0.6885	 Sentiment Loss:3.6749	Valence Loss:0.1444	 Arousal Loss:0.2443	
[2025-11-12 02:41:41,589][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1890/2792.0]	 Loss Sum:12.5591	forward Loss:4.6773;1.4379	 backward Loss:3.1979;2.8505	 Sentiment Loss:0.0198	Valence Loss:0.8278	 Arousal Loss:1.0508	
[2025-11-12 02:41:45,159][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1900/2792.0]	 Loss Sum:32.1352	forward Loss:2.3714;15.5677	 backward Loss:11.4275;2.6365	 Sentiment Loss:0.0163	Valence Loss:0.5442	 Arousal Loss:0.0343	
[2025-11-12 02:41:48,733][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1910/2792.0]	 Loss Sum:26.6232	forward Loss:1.5816;11.1245	 backward Loss:12.193;1.0445	 Sentiment Loss:0.6176	Valence Loss:0.2005	 Arousal Loss:0.1092	
[2025-11-12 02:41:52,314][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1920/2792.0]	 Loss Sum:27.5733	forward Loss:3.3704;12.5995	 backward Loss:8.3533;2.5789	 Sentiment Loss:0.0175	Valence Loss:3.1342	 Arousal Loss:0.1344	
[2025-11-12 02:41:55,894][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1930/2792.0]	 Loss Sum:27.4814	forward Loss:11.424;5.0628	 backward Loss:7.2889;3.2405	 Sentiment Loss:0.3089	Valence Loss:0.2407	 Arousal Loss:0.5405	
[2025-11-12 02:41:59,473][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1940/2792.0]	 Loss Sum:13.2228	forward Loss:0.9066;3.5968	 backward Loss:4.239;0.5968	 Sentiment Loss:3.8225	Valence Loss:0.2243	 Arousal Loss:0.0806	
[2025-11-12 02:42:03,046][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1950/2792.0]	 Loss Sum:5.1209	forward Loss:1.0111;0.9099	 backward Loss:2.6236;0.3298	 Sentiment Loss:0.0179	Valence Loss:1.0771	 Arousal Loss:0.0657	
[2025-11-12 02:42:06,620][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1960/2792.0]	 Loss Sum:19.3176	forward Loss:1.9317;3.4909	 backward Loss:10.8283;2.3299	 Sentiment Loss:0.6714	Valence Loss:0.0836	 Arousal Loss:0.2438	
[2025-11-12 02:42:10,192][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1970/2792.0]	 Loss Sum:8.9897	forward Loss:1.1433;1.425	 backward Loss:3.8283;2.2315	 Sentiment Loss:0.1341	Valence Loss:0.7806	 Arousal Loss:0.3564	
[2025-11-12 02:42:13,765][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1980/2792.0]	 Loss Sum:6.802	forward Loss:0.3081;2.1256	 backward Loss:2.0532;0.4441	 Sentiment Loss:1.0331	Valence Loss:1.6715	 Arousal Loss:2.5183	
[2025-11-12 02:42:17,334][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[1990/2792.0]	 Loss Sum:19.0545	forward Loss:4.8126;4.0728	 backward Loss:5.893;3.9153	 Sentiment Loss:0.2914	Valence Loss:0.0966	 Arousal Loss:0.251	
[2025-11-12 02:42:20,913][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2000/2792.0]	 Loss Sum:10.2148	forward Loss:2.8552;2.1732	 backward Loss:3.7845;0.5362	 Sentiment Loss:0.5971	Valence Loss:0.3047	 Arousal Loss:1.0379	
[2025-11-12 02:42:24,486][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2010/2792.0]	 Loss Sum:15.1402	forward Loss:1.5914;3.3408	 backward Loss:5.7325;2.12	 Sentiment Loss:2.0479	Valence Loss:1.4044	 Arousal Loss:0.1345	
[2025-11-12 02:42:28,063][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2020/2792.0]	 Loss Sum:5.2893	forward Loss:2.0655;1.0941	 backward Loss:0.9921;1.0464	 Sentiment Loss:0.0186	Valence Loss:0.2801	 Arousal Loss:0.0833	
[2025-11-12 02:42:31,646][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2030/2792.0]	 Loss Sum:13.0857	forward Loss:2.1184;4.2769	 backward Loss:2.6129;2.9647	 Sentiment Loss:0.1644	Valence Loss:2.9337	 Arousal Loss:1.8086	
[2025-11-12 02:42:35,215][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2040/2792.0]	 Loss Sum:13.0838	forward Loss:3.3364;1.881	 backward Loss:3.7157;4.0248	 Sentiment Loss:0.0331	Valence Loss:0.3112	 Arousal Loss:0.1528	
[2025-11-12 02:42:38,790][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2050/2792.0]	 Loss Sum:12.8449	forward Loss:1.6806;3.6735	 backward Loss:3.5496;3.8257	 Sentiment Loss:0.0104	Valence Loss:0.1241	 Arousal Loss:0.4016	
[2025-11-12 02:42:42,368][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2060/2792.0]	 Loss Sum:10.4841	forward Loss:0.1981;5.4617	 backward Loss:4.0005;0.2035	 Sentiment Loss:0.0348	Valence Loss:2.8245	 Arousal Loss:0.1029	
[2025-11-12 02:42:45,939][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2070/2792.0]	 Loss Sum:7.543	forward Loss:2.1828;1.4058	 backward Loss:1.7803;1.5514	 Sentiment Loss:0.5568	Valence Loss:0.2139	 Arousal Loss:0.1151	
[2025-11-12 02:42:49,499][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2080/2792.0]	 Loss Sum:42.8958	forward Loss:2.6404;18.6841	 backward Loss:13.9272;7.1642	 Sentiment Loss:0.017	Valence Loss:1.3762	 Arousal Loss:0.9378	
[2025-11-12 02:42:53,068][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2090/2792.0]	 Loss Sum:11.4461	forward Loss:0.475;5.0876	 backward Loss:2.7982;2.9428	 Sentiment Loss:0.1156	Valence Loss:0.0361	 Arousal Loss:0.0983	
[2025-11-12 02:42:56,645][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2100/2792.0]	 Loss Sum:52.0819	forward Loss:12.7758;11.0277	 backward Loss:11.6212;16.4093	 Sentiment Loss:0.1019	Valence Loss:0.6444	 Arousal Loss:0.0856	
[2025-11-12 02:43:00,217][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2110/2792.0]	 Loss Sum:8.2749	forward Loss:2.1442;1.5122	 backward Loss:3.3141;1.2235	 Sentiment Loss:0.0133	Valence Loss:0.1775	 Arousal Loss:0.1605	
[2025-11-12 02:43:03,793][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2120/2792.0]	 Loss Sum:17.5067	forward Loss:3.2284;3.9012	 backward Loss:8.9812;0.9767	 Sentiment Loss:0.2818	Valence Loss:0.6379	 Arousal Loss:0.0491	
[2025-11-12 02:43:07,372][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2130/2792.0]	 Loss Sum:5.3048	forward Loss:1.6607;1.6854	 backward Loss:0.5333;1.3691	 Sentiment Loss:0.0129	Valence Loss:0.0886	 Arousal Loss:0.128	
[2025-11-12 02:43:10,959][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2140/2792.0]	 Loss Sum:15.6636	forward Loss:1.711;5.2533	 backward Loss:4.1065;1.6522	 Sentiment Loss:1.3227	Valence Loss:6.2211	 Arousal Loss:1.8684	
[2025-11-12 02:43:14,553][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2150/2792.0]	 Loss Sum:22.9025	forward Loss:4.5222;6.7839	 backward Loss:6.6211;4.6983	 Sentiment Loss:0.0255	Valence Loss:0.6058	 Arousal Loss:0.6517	
[2025-11-12 02:43:18,117][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2160/2792.0]	 Loss Sum:8.7706	forward Loss:0.833;3.9247	 backward Loss:2.7918;0.7171	 Sentiment Loss:0.4273	Valence Loss:0.292	 Arousal Loss:0.0916	
[2025-11-12 02:43:21,696][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2170/2792.0]	 Loss Sum:4.2058	forward Loss:0.7396;0.5293	 backward Loss:0.4065;0.6319	 Sentiment Loss:1.8175	Valence Loss:0.2464	 Arousal Loss:0.1588	
[2025-11-12 02:43:25,273][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2180/2792.0]	 Loss Sum:35.1558	forward Loss:5.0678;4.7935	 backward Loss:20.2003;2.2659	 Sentiment Loss:2.6041	Valence Loss:1.0253	 Arousal Loss:0.0958	
[2025-11-12 02:43:28,841][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2190/2792.0]	 Loss Sum:47.0306	forward Loss:19.5287;4.9822	 backward Loss:3.8244;13.6806	 Sentiment Loss:4.088	Valence Loss:1.5008	 Arousal Loss:3.1324	
[2025-11-12 02:43:32,411][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2200/2792.0]	 Loss Sum:11.861	forward Loss:1.187;3.3712	 backward Loss:6.0229;0.9734	 Sentiment Loss:0.2543	Valence Loss:0.1344	 Arousal Loss:0.1263	
[2025-11-12 02:43:35,979][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2210/2792.0]	 Loss Sum:5.8697	forward Loss:2.0052;0.6308	 backward Loss:0.6229;2.5257	 Sentiment Loss:0.0599	Valence Loss:0.072	 Arousal Loss:0.0543	
[2025-11-12 02:43:39,561][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2220/2792.0]	 Loss Sum:9.4655	forward Loss:3.4699;1.0509	 backward Loss:3.7378;0.8088	 Sentiment Loss:0.0231	Valence Loss:1.7781	 Arousal Loss:0.0961	
[2025-11-12 02:43:43,139][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2230/2792.0]	 Loss Sum:19.5481	forward Loss:2.3871;8.0494	 backward Loss:6.714;1.5504	 Sentiment Loss:0.6489	Valence Loss:0.9206	 Arousal Loss:0.0713	
[2025-11-12 02:43:46,717][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2240/2792.0]	 Loss Sum:9.0478	forward Loss:1.8305;1.7386	 backward Loss:4.82;0.4371	 Sentiment Loss:0.1371	Valence Loss:0.332	 Arousal Loss:0.0907	
[2025-11-12 02:43:50,310][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2250/2792.0]	 Loss Sum:18.0478	forward Loss:3.0388;3.608	 backward Loss:6.1228;5.1366	 Sentiment Loss:0.0768	Valence Loss:0.0863	 Arousal Loss:0.2376	
[2025-11-12 02:43:53,886][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2260/2792.0]	 Loss Sum:7.6823	forward Loss:3.4707;0.7829	 backward Loss:0.8696;1.6464	 Sentiment Loss:0.845	Valence Loss:0.2492	 Arousal Loss:0.089	
[2025-11-12 02:43:57,456][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2270/2792.0]	 Loss Sum:9.5111	forward Loss:1.1027;2.3833	 backward Loss:3.8425;2.0375	 Sentiment Loss:0.0074	Valence Loss:0.6254	 Arousal Loss:0.0629	
[2025-11-12 02:44:01,026][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2280/2792.0]	 Loss Sum:5.7735	forward Loss:0.8808;1.326	 backward Loss:2.9936;0.2967	 Sentiment Loss:0.2127	Valence Loss:0.1934	 Arousal Loss:0.1252	
[2025-11-12 02:44:04,602][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2290/2792.0]	 Loss Sum:33.2971	forward Loss:10.3937;8.7893	 backward Loss:8.1248;5.403	 Sentiment Loss:0.0204	Valence Loss:2.5213	 Arousal Loss:0.3081	
[2025-11-12 02:44:08,177][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2300/2792.0]	 Loss Sum:7.7699	forward Loss:2.2116;1.4867	 backward Loss:1.9492;1.85	 Sentiment Loss:0.1412	Valence Loss:0.2829	 Arousal Loss:0.3735	
[2025-11-12 02:44:11,753][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2310/2792.0]	 Loss Sum:4.8816	forward Loss:1.2136;1.3186	 backward Loss:1.5182;0.4332	 Sentiment Loss:0.21	Valence Loss:0.2303	 Arousal Loss:0.7104	
[2025-11-12 02:44:15,332][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2320/2792.0]	 Loss Sum:2.9028	forward Loss:1.041;0.4072	 backward Loss:0.9674;0.4175	 Sentiment Loss:0.0236	Valence Loss:0.1734	 Arousal Loss:0.0571	
[2025-11-12 02:44:18,912][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2330/2792.0]	 Loss Sum:26.686	forward Loss:6.7387;10.2712	 backward Loss:8.6305;0.847	 Sentiment Loss:0.0695	Valence Loss:0.4829	 Arousal Loss:0.1625	
[2025-11-12 02:44:22,489][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2340/2792.0]	 Loss Sum:7.4862	forward Loss:2.6687;0.4885	 backward Loss:0.3121;2.2017	 Sentiment Loss:1.7537	Valence Loss:0.1739	 Arousal Loss:0.1337	
[2025-11-12 02:44:26,065][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2350/2792.0]	 Loss Sum:14.8058	forward Loss:0.8129;3.2129	 backward Loss:5.5269;2.0054	 Sentiment Loss:3.2266	Valence Loss:0.0725	 Arousal Loss:0.0336	
[2025-11-12 02:44:29,638][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2360/2792.0]	 Loss Sum:11.9901	forward Loss:0.6674;4.4661	 backward Loss:4.9062;1.7864	 Sentiment Loss:0.0634	Valence Loss:0.4142	 Arousal Loss:0.0891	
[2025-11-12 02:44:33,210][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2370/2792.0]	 Loss Sum:9.595	forward Loss:1.7066;2.5398	 backward Loss:3.2657;1.5311	 Sentiment Loss:0.4822	Valence Loss:0.1428	 Arousal Loss:0.2049	
[2025-11-12 02:44:36,787][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2380/2792.0]	 Loss Sum:17.5619	forward Loss:4.2164;1.5774	 backward Loss:5.1441;6.3562	 Sentiment Loss:0.0279	Valence Loss:0.492	 Arousal Loss:0.7077	
[2025-11-12 02:44:40,355][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2390/2792.0]	 Loss Sum:17.0067	forward Loss:3.3354;6.3922	 backward Loss:3.8605;3.134	 Sentiment Loss:0.1433	Valence Loss:0.1503	 Arousal Loss:0.556	
[2025-11-12 02:44:43,920][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2400/2792.0]	 Loss Sum:8.5889	forward Loss:1.3456;2.4832	 backward Loss:2.0745;0.6159	 Sentiment Loss:2.0149	Valence Loss:0.141	 Arousal Loss:0.133	
[2025-11-12 02:44:47,487][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2410/2792.0]	 Loss Sum:19.38	forward Loss:4.2128;4.8297	 backward Loss:1.6044;8.2057	 Sentiment Loss:0.0212	Valence Loss:2.421	 Arousal Loss:0.11	
[2025-11-12 02:44:51,045][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2420/2792.0]	 Loss Sum:11.6503	forward Loss:1.1379;4.1814	 backward Loss:4.2197;1.3009	 Sentiment Loss:0.6861	Valence Loss:0.5325	 Arousal Loss:0.0886	
[2025-11-12 02:44:54,623][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2430/2792.0]	 Loss Sum:9.7937	forward Loss:2.6817;1.1829	 backward Loss:3.1296;0.8646	 Sentiment Loss:1.8366	Valence Loss:0.4476	 Arousal Loss:0.0439	
[2025-11-12 02:44:58,211][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2440/2792.0]	 Loss Sum:9.3217	forward Loss:3.4312;1.9095	 backward Loss:1.1056;2.569	 Sentiment Loss:0.2558	Valence Loss:0.1183	 Arousal Loss:0.1349	
[2025-11-12 02:45:01,777][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2450/2792.0]	 Loss Sum:11.2738	forward Loss:2.629;1.6014	 backward Loss:3.3964;3.2568	 Sentiment Loss:0.2414	Valence Loss:0.4026	 Arousal Loss:0.3412	
[2025-11-12 02:45:05,349][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2460/2792.0]	 Loss Sum:8.6337	forward Loss:0.8403;3.5174	 backward Loss:3.0378;1.1699	 Sentiment Loss:0.037	Valence Loss:0.0995	 Arousal Loss:0.0571	
[2025-11-12 02:45:08,932][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2470/2792.0]	 Loss Sum:33.1827	forward Loss:11.9648;3.2613	 backward Loss:10.2294;2.2968	 Sentiment Loss:5.3928	Valence Loss:0.1393	 Arousal Loss:0.0487	
[2025-11-12 02:45:12,504][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2480/2792.0]	 Loss Sum:7.1359	forward Loss:3.9187;0.5265	 backward Loss:0.4844;2.048	 Sentiment Loss:0.0398	Valence Loss:0.3608	 Arousal Loss:0.2321	
[2025-11-12 02:45:16,079][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2490/2792.0]	 Loss Sum:19.3966	forward Loss:1.0837;6.482	 backward Loss:7.5297;0.8717	 Sentiment Loss:3.3612	Valence Loss:0.0362	 Arousal Loss:0.3047	
[2025-11-12 02:45:19,643][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2500/2792.0]	 Loss Sum:9.5101	forward Loss:3.0117;0.3971	 backward Loss:0.4342;1.3287	 Sentiment Loss:4.0837	Valence Loss:0.4855	 Arousal Loss:0.7872	
[2025-11-12 02:45:23,209][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2510/2792.0]	 Loss Sum:19.4004	forward Loss:7.2902;2.276	 backward Loss:4.3113;4.3714	 Sentiment Loss:1.1065	Valence Loss:0.1853	 Arousal Loss:0.0398	
[2025-11-12 02:45:26,781][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2520/2792.0]	 Loss Sum:13.1528	forward Loss:3.0104;3.0077	 backward Loss:1.8841;3.4796	 Sentiment Loss:1.1924	Valence Loss:1.4689	 Arousal Loss:1.4236	
[2025-11-12 02:45:30,351][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2530/2792.0]	 Loss Sum:5.5798	forward Loss:0.4377;1.9866	 backward Loss:1.8449;1.0288	 Sentiment Loss:0.2179	Valence Loss:0.2589	 Arousal Loss:0.0604	
[2025-11-12 02:45:33,914][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2540/2792.0]	 Loss Sum:3.9056	forward Loss:0.2653;0.6341	 backward Loss:0.8665;0.4604	 Sentiment Loss:1.2868	Valence Loss:1.7151	 Arousal Loss:0.2471	
[2025-11-12 02:45:37,492][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2550/2792.0]	 Loss Sum:15.4496	forward Loss:1.041;4.1907	 backward Loss:8.539;1.3783	 Sentiment Loss:0.2719	Valence Loss:0.102	 Arousal Loss:0.0413	
[2025-11-12 02:45:41,065][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2560/2792.0]	 Loss Sum:5.685	forward Loss:0.2312;0.5861	 backward Loss:4.6041;0.0963	 Sentiment Loss:0.0284	Valence Loss:0.3042	 Arousal Loss:0.3904	
[2025-11-12 02:45:44,635][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2570/2792.0]	 Loss Sum:1.4548	forward Loss:0.241;0.5811	 backward Loss:0.4047;0.0949	 Sentiment Loss:0.0068	Valence Loss:0.5629	 Arousal Loss:0.0695	
[2025-11-12 02:45:48,208][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2580/2792.0]	 Loss Sum:52.2975	forward Loss:11.3868;3.344	 backward Loss:34.2423;2.2618	 Sentiment Loss:0.8971	Valence Loss:0.7732	 Arousal Loss:0.055	
[2025-11-12 02:45:51,773][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2590/2792.0]	 Loss Sum:11.9694	forward Loss:1.0161;1.2394	 backward Loss:6.9401;0.5047	 Sentiment Loss:2.1774	Valence Loss:0.4092	 Arousal Loss:0.049	
[2025-11-12 02:45:55,338][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2600/2792.0]	 Loss Sum:14.0778	forward Loss:1.6396;1.216	 backward Loss:2.3345;2.0855	 Sentiment Loss:6.4616	Valence Loss:1.1802	 Arousal Loss:0.5227	
[2025-11-12 02:45:58,902][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2610/2792.0]	 Loss Sum:23.4563	forward Loss:5.2011;6.1577	 backward Loss:9.8153;1.8357	 Sentiment Loss:0.2801	Valence Loss:0.1375	 Arousal Loss:0.6947	
[2025-11-12 02:46:02,466][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2620/2792.0]	 Loss Sum:17.3993	forward Loss:5.3233;1.8084	 backward Loss:6.4587;3.6035	 Sentiment Loss:0.1082	Valence Loss:0.3245	 Arousal Loss:0.162	
[2025-11-12 02:46:06,039][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2630/2792.0]	 Loss Sum:18.9692	forward Loss:1.9004;1.9951	 backward Loss:10.5386;0.3885	 Sentiment Loss:4.0383	Valence Loss:0.4512	 Arousal Loss:0.0906	
[2025-11-12 02:46:09,612][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2640/2792.0]	 Loss Sum:19.9736	forward Loss:8.1443;1.2888	 backward Loss:2.0543;6.6437	 Sentiment Loss:1.695	Valence Loss:0.4884	 Arousal Loss:0.2492	
[2025-11-12 02:46:13,182][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2650/2792.0]	 Loss Sum:35.7393	forward Loss:6.2746;10.1602	 backward Loss:5.247;12.9228	 Sentiment Loss:1.0867	Valence Loss:0.066	 Arousal Loss:0.1741	
[2025-11-12 02:46:16,750][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2660/2792.0]	 Loss Sum:14.0317	forward Loss:4.6003;1.0252	 backward Loss:1.7302;2.1681	 Sentiment Loss:4.3221	Valence Loss:0.3917	 Arousal Loss:0.5379	
[2025-11-12 02:46:20,341][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2670/2792.0]	 Loss Sum:30.3219	forward Loss:10.3211;4.5339	 backward Loss:11.7198;3.4267	 Sentiment Loss:0.1474	Valence Loss:0.5269	 Arousal Loss:0.3382	
[2025-11-12 02:46:23,919][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2680/2792.0]	 Loss Sum:23.2835	forward Loss:2.8424;2.7883	 backward Loss:11.5066;1.385	 Sentiment Loss:4.6668	Valence Loss:0.2176	 Arousal Loss:0.254	
[2025-11-12 02:46:27,491][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2690/2792.0]	 Loss Sum:5.087	forward Loss:1.6173;0.5625	 backward Loss:0.6123;2.0671	 Sentiment Loss:0.1079	Valence Loss:0.4708	 Arousal Loss:0.1292	
[2025-11-12 02:46:31,065][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2700/2792.0]	 Loss Sum:15.9206	forward Loss:1.1188;6.3601	 backward Loss:7.394;0.4501	 Sentiment Loss:0.5468	Valence Loss:0.155	 Arousal Loss:0.1	
[2025-11-12 02:46:34,630][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2710/2792.0]	 Loss Sum:15.2029	forward Loss:2.9229;1.6878	 backward Loss:6.9904;1.447	 Sentiment Loss:1.7966	Valence Loss:0.7921	 Arousal Loss:0.9988	
[2025-11-12 02:46:38,197][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2720/2792.0]	 Loss Sum:11.6829	forward Loss:0.9977;2.397	 backward Loss:2.7431;1.3063	 Sentiment Loss:3.9879	Valence Loss:0.5544	 Arousal Loss:0.7002	
[2025-11-12 02:46:41,768][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2730/2792.0]	 Loss Sum:21.6909	forward Loss:2.0202;6.3444	 backward Loss:7.0706;2.5444	 Sentiment Loss:3.4214	Valence Loss:1.198	 Arousal Loss:0.2514	
[2025-11-12 02:46:45,337][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2740/2792.0]	 Loss Sum:15.9044	forward Loss:0.275;5.4477	 backward Loss:9.756;0.2812	 Sentiment Loss:0.0152	Valence Loss:0.5218	 Arousal Loss:0.1246	
[2025-11-12 02:46:48,911][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2750/2792.0]	 Loss Sum:4.078	forward Loss:0.4869;1.9007	 backward Loss:0.739;0.546	 Sentiment Loss:0.2578	Valence Loss:0.1851	 Arousal Loss:0.5526	
[2025-11-12 02:46:52,495][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2760/2792.0]	 Loss Sum:24.2885	forward Loss:5.7473;3.3239	 backward Loss:8.0047;3.8808	 Sentiment Loss:3.0403	Valence Loss:0.8292	 Arousal Loss:0.6284	
[2025-11-12 02:46:56,060][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2770/2792.0]	 Loss Sum:14.5638	forward Loss:2.7408;1.5941	 backward Loss:3.2163;2.0339	 Sentiment Loss:4.9347	Valence Loss:0.1346	 Arousal Loss:0.0851	
[2025-11-12 02:46:59,633][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2780/2792.0]	 Loss Sum:47.0833	forward Loss:13.2639;11.2803	 backward Loss:10.8942;11.4336	 Sentiment Loss:0.0985	Valence Loss:0.4084	 Arousal Loss:0.1555	
[2025-11-12 02:47:03,213][run_task2&3_trainer_multilingual.py][line:1114][INFO] Epoch:[1/1]	 Batch:[2790/2792.0]	 Loss Sum:4.183	forward Loss:0.4418;0.7046	 backward Loss:1.7559;0.2037	 Sentiment Loss:1.0489	Valence Loss:0.0841	 Arousal Loss:0.0561	
[2025-11-12 02:47:03,911][run_task2&3_trainer_multilingual.py][line:1126][INFO] dev
[2025-11-12 02:47:29,619][run_task2&3_trainer_multilingual.py][line:467][INFO] Triplet - Precision: 0.4090909087190082	Recall: 0.3360716950440092	F1: 0.3690031945360948
[2025-11-12 02:47:29,619][run_task2&3_trainer_multilingual.py][line:472][INFO] Aspect - Precision: 0.7783400801838664	Recall: 0.6727909005487394	F1: 0.7217263907528396
[2025-11-12 02:47:29,619][run_task2&3_trainer_multilingual.py][line:477][INFO] Opinion - Precision: 0.6597077237372571	Recall: 0.5068163588558008	F1: 0.5732421384550774
[2025-11-12 02:47:29,619][run_task2&3_trainer_multilingual.py][line:483][INFO] Aspect-Category - Precision: 0.5444126069298828	Recall: 0.456730768864799	F1: 0.4967315295466814
[2025-11-12 02:47:29,619][run_task2&3_trainer_multilingual.py][line:491][INFO] Aspect-Opinion - Precision: 0.5409090904173554	Recall: 0.4443614634470788	F1: 0.48790438345032305
[2025-11-12 02:47:29,620][run_task2&3_trainer_multilingual.py][line:1132][INFO] Model saved after epoch 1
[2025-11-12 02:47:30,502][run_task2&3_trainer_multilingual.py][line:1139][INFO] loading model......
[2025-11-12 02:47:31,143][run_task2&3_trainer_multilingual.py][line:1142][INFO] inference......
